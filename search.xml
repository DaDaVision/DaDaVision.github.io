<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[常见查找算法总结]]></title>
    <url>%2F2018%2F08%2F22%2F%E5%B8%B8%E8%A7%81%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[阅读目录 顺序查找 二分查找 插值查找 斐波那契查找 树表查找 分块查找 哈希查找 ​ 查找是在大量的信息中寻找一个特定的信息元素，在计算机应用中，查找是常用的基本运算，例如编译程序中符号表的查找。本文简单概括性的介绍了常见的七种查找算法，说是七种，其实二分查找、插值查找以及斐波那契查找都可以归为一类——插值查找。插值查找和斐波那契查找是在二分查找的基础上的优化查找算法。 查找定义：根据给定的某个值，在查找表中确定一个其关键字等于给定值的数据元素（或记录）。 查找算法分类： 1）静态查找和动态查找； 注：静态或者动态都是针对查找表而言的。动态表指查找表中有删除和插入操作的表。 2）无序查找和有序查找。 无序查找：被查找数列有序无序均可； 有序查找：被查找数列必须为有序数列。 平均查找长度（Average Search Length，ASL）：需和指定key进行比较的关键字的个数的期望值，称为查找算法在查找成功时的平均查找长度。 对于含有n个数据元素的查找表，查找成功的平均查找长度为：ASL = Pi*Ci的和。 Pi：查找表中第i个数据元素的概率。 Ci：找到第i个数据元素时已经比较过的次数。 1. 顺序查找 说明：顺序查找适合于存储结构为顺序存储或链接存储的线性表。 基本思想：顺序查找也称为线形查找，属于无序查找算法。从数据结构线形表的一端开始，顺序扫描，依次将扫描到的结点关键字与给定值k相比较，若相等则表示查找成功；若扫描结束仍没有找到关键字等于k的结点，表示查找失败。 复杂度分析： 查找成功时的平均查找长度为：（假设每个数据元素的概率相等） ASL = 1/n(1+2+3+…+n) = (n+1)/2 ; 当查找不成功时，需要n+1次比较，时间复杂度为O(n); 所以，顺序查找的时间复杂度为O(n)。 （1） C++实现：123456789//顺序查找int Sequence_Search(int a[], int value, int n)&#123; int i; for(i=0; i&lt;n; i++) if(a[i]==value) return i; return -1;&#125; （2）python实现： 1234567def Sequence_Search(nums, target): if len(nums)==0: return False for i in range(len(nums)): if nums[i]==target: return True return False 2. 二分查找/折半查找 说明：元素必须是有序的，如果是无序的则要先进行排序操作。 基本思想：也称为是折半查找，属于有序查找算法。用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。 复杂度分析：最坏情况下，关键词比较次数为log2(n+1)，且期望时间复杂度为O(log2n)； 注：折半查找的前提条件是需要有序表顺序存储，对于静态查找表，一次排序后不再变化，折半查找能得到不错的效率。但对于需要频繁执行插入或删除操作的数据集来说，维护有序的排序会带来不小的工作量，那就不建议使用。 （1） C++实现：123456789101112131415161718192021222324252627282930//二分查找，递归版本int BinarySearch2(int a[], int value, int low, int high)&#123; int mid = low+(high-low)/2; if(a[mid]==value) return mid; if(a[mid]&gt;value) return BinarySearch2(a, value, low, mid-1); if(a[mid]&lt;value) return BinarySearch2(a, value, mid+1, high);&#125;//二分查找（折半查找），非递归版本int BinarySearch1(int a[], int value, int n)&#123; int low, high, mid; low = 0; high = n-1; while(low&lt;=high) &#123; mid = (low+high)/2; if(a[mid]==value) return mid; if(a[mid]&gt;value) high = mid-1; if(a[mid]&lt;value) low = mid+1; &#125; return -1;&#125; （2） python版本123456789101112131415161718192021222324252627282930313233343536373839#-----------------递归二分查找------------------def binary_Search(nums,target,left,right): if len(nums)==0: return False mid=(left+right)//2 while left&lt;=right: if nums[mid]&gt;target: return binary_Search(nums, target, left, mid-1) elif nums[mid]&lt;target: return binary_Search(nums, target, mid+1, right) else: return midif __name__ == '__main__': list = [1, 5, 7, 8, 22, 54, 99, 123, 200, 222, 444] low=0 high=len(list)-1 result = binary_Search(list,444,low,high) print(result)#-------------------非递归查找------------------------def binary_Search(nums,target): if len(nums)==0: return False low = 0 high = len(nums)-1 while low &lt;= high: mid = (low+high)//2 if nums[mid] == target: return mid elif nums[mid] &lt; target: low = mid + 1 else: high = mid - 1 return Falseif __name__ == '__main__': list = [1, 5, 7, 8, 22, 54, 99, 123, 200, 222, 444] result = binary_Search(list,444) print(result) ​ 时间复杂度分析 最坏情况下，关键词比较次数为⌊log2n⌋+1，最好情况就是1，所以二分查找的时间复杂度为O(logn)。它显然好于顺序查找的O(n)。 3. 插值查找 在介绍插值查找之前，首先考虑一个新问题，为什么上述算法一定要是折半，而不是折四分之一或者折更多呢？ 打个比方，在英文字典里面查“apple”，你下意识翻开字典是翻前面的书页还是后面的书页呢？如果再让你查“zoo”，你又怎么查？很显然，这里你绝对不会是从中间开始查起，而是有一定目的的往前或往后翻。 同样的，比如要在取值范围1 ~ 10000 之间 100 个元素从小到大均匀分布的数组中查找5， 我们自然会考虑从数组下标较小的开始查找。 经过以上分析，折半查找这种查找方式，不是自适应的（也就是说是傻瓜式的）。二分查找中查找点计算如下： mid=(low+high)/2, 即mid=low+1/2*(high-low); 通过类比，我们可以将查找的点改进为如下： mid=low+(key-a[low])/(a[high]-a[low])*(high-low)， 也就是将上述的比例参数1/2改进为自适应的，根据关键字在整个有序表中所处的位置，让mid值的变化更靠近关键字key，这样也就间接地减少了比较次数。 基本思想：基于二分查找算法，将查找点的选择改进为自适应选择，可以提高查找效率。当然，差值查找也属于有序查找。 注：对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。 复杂度分析：查找成功或者失败的时间复杂度均为O(log2(log2n))。 （1） C++实现：1234567891011//插值查找int InsertionSearch(int a[], int value, int low, int high)&#123; int mid = low+(value-a[low])/(a[high]-a[low])*(high-low); if(a[mid]==value) return mid; if(a[mid]&gt;value) return InsertionSearch(a, value, low, mid-1); if(a[mid]&lt;value) return InsertionSearch(a, value, mid+1, high);&#125; （2）python代码 1234567891011121314151617181920212223242526# 插值查找算法# 时间复杂度O(log(n))def insert_search(lis, key): low = 0 high = len(lis) - 1 time = 0 while low &lt; high: time += 1 # 计算mid值是插值算法的核心代码 mid = low + int((high - low) * (key - lis[low])/(lis[high] - lis[low])) print("mid=%s, low=%s, high=%s" % (mid, low, high)) if key &lt; lis[mid]: high = mid - 1 elif key &gt; lis[mid]: low = mid + 1 else: # 打印查找的次数 print("times: %s" % time) return mid print("times: %s" % time) return Falseif __name__ == '__main__': LIST = [1, 5, 7, 8, 22, 54, 99, 123, 200, 222, 444] result = insert_search(LIST, 444) print(result) ​ 时间复杂度分析 ​ 它的时间复杂度跟二分查找的时间复杂度一样，为O(logn)。需要注意的是对于表长较大，而关键字分布又比较均匀的查找表来说，插值查找算法的平均性能比折半查找要好的多。反之，数组中如果分布非常不均匀，那么插值查找未必是很合适的选择。 4. 斐波那契查找 在介绍斐波那契查找算法之前，我们先介绍一下很它紧密相连并且大家都熟知的一个概念——黄金分割。 黄金比例又称黄金分割，是指事物各部分间一定的数学比例关系，即将整体一分为二，较大部分与较小部分之比等于整体与较大部分之比，其比值约为1:0.618或1.618:1。 0.618被公认为最具有审美意义的比例数字，这个数值的作用不仅仅体现在诸如绘画、雕塑、音乐、建筑等艺术领域，而且在管理、工程设计等方面也有着不可忽视的作用。因此被称为黄金分割。 大家记不记得斐波那契数列：1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89…….（从第三个数开始，后边每一个数都是前两个数的和）。然后我们会发现，随着斐波那契数列的递增，前后两个数的比值会越来越接近0.618，利用这个特性，我们就可以将黄金比例运用到查找技术中。 基本思想：也是二分查找的一种提升算法，通过运用黄金比例的概念在数列中选择查找点进行查找，提高查找效率。同样地，斐波那契查找也属于一种有序查找算法。 相对于折半查找，一般将待比较的key值与第mid=（low+high）/2位置的元素比较，比较结果分三种情况： 1）相等，mid位置的元素即为所求 2）&gt;，low=mid+1; ​ 3）&lt;，high=mid-1。 斐波那契查找与折半查找很相似，他是根据斐波那契序列的特点对有序表进行分割的。他要求开始表中记录的个数为某个斐波那契数小1，及n=F(k)-1; 开始将k值与第F(k-1)位置的记录进行比较(及mid=low+F(k-1)-1),比较结果也分为三种 1）相等，mid位置的元素即为所求 2）&gt;，low=mid+1,k-=2; 说明：low=mid+1说明待查找的元素在[mid+1,high]范围内，k-=2 说明范围[mid+1,high]内的元素个数为n-(F(k-1))= Fk-1-F(k-1)=Fk-F(k-1)-1=F(k-2)-1个，所以可以递归的应用斐波那契查找。 3）&lt;，high=mid-1,k-=1。 说明：low=mid+1说明待查找的元素在[low,mid-1]范围内，k-=1 说明范围[low,mid-1]内的元素个数为F(k-1)-1个，所以可以递归 的应用斐波那契查找。 复杂度分析：最坏情况下，时间复杂度为O(log2n)，且其期望复杂度也为O(log2n**)。**]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>查找算法</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10大经典排序算法总结]]></title>
    <url>%2F2018%2F08%2F21%2F10%E5%A4%A7%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[0、算法概述0.1 算法分类①：十种常见排序算法可以分为两大类： 非线性时间比较类排序：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此称为非线性时间比较类排序。 线性时间非比较类排序：不通过比较来决定元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此称为线性时间非比较类排序。 ②：另外一种分类排序方法——我们通常所说的排序算法往往指的是内部排序算法，即数据记录在内存中进行排序。 排序算法大体可分为两种： 一种是比较排序，时间复杂度O(nlogn) ~ O(n^2)，主要有：冒泡排序，选择排序，插入排序，归并排序，堆排序，快速排序等。 另一种是非比较排序，时间复杂度可以达到O(n)，主要有：计数排序，基数排序，桶排序等。 0.2 算法复杂度 0.3 相关概念 稳定：如果a原本在b前面，而a=b，排序之后a仍然在b的前面。通俗地讲就是保证排序前后两个相等的数的相对顺序不变。 不稳定：如果a原本在b的前面，而a=b，排序之后 a 可能会出现在 b 的后面。 时间复杂度：对排序数据的总的操作次数。反映当n变化时，操作次数呈现什么规律。 空间复杂度：是指算法在计算机内执行时所需存储空间的度量，它也是数据规模n的函数。 ​ ​ 对于不稳定的排序算法，只要举出一个实例，即可说明它的不稳定性；而对于稳定的排序算法，必须对算法进行分析从而得到稳定的特性。需要注意的是，排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。 例如，对于冒泡排序，原本是稳定的排序算法，如果将记录交换的条件改成A[i] &gt;= A[i + 1]，则两个相等的记录就会交换位置，从而变成不稳定的排序算法。 其次，说一下排序算法稳定性的好处。排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，前一个键排序的结果可以为后一个键排序所用。基数排序就是这样，先按低位排序，逐次按高位排序，低位排序后元素的顺序在高位也相同时是不会改变的。 0.4 技巧记忆口诀： 不稳定排序算法口诀：快些选队（快希选堆）其余为稳定的。 算法复杂度和关键字顺序无关的有： 顺口溜：一堆（堆排序）海龟（归并排序）选（选择排序）基（基数排序）友 快些以 nlog2 n 的速度归队 快=快速排序，些=希尔排序，归=归并排序，队=堆排序 这四种排序算法，时间都是 n log2 n 的，除了这四个之外，其他的排序算法平均时间都为 n^2 一趟排序，保证一个元素为最终位置的有两类排序算法：交换类（冒泡和快速）排序和选择类排序（简单和堆） 元素比较次数和原始序列无关的算法：简单选择排序，折半插入排序 排序趟数和原序列有关的算法：交换类，其余类无关 借助于比较进行排序的算法，在最坏的时候，最好的时间复杂度为 n log2 n 堆排序和简单选择排序的时间复杂度和初始序列无关 0.5 总结：（1）在比较类排序中，归并排序号称最快，其次是快速排序和堆排序，两者不相伯仲，但是有一点需要注意，数据初始排序状态对堆排序不会产生太大的影响，而快速排序却恰恰相反。 （2）线性时间非比较类排序一般要优于非线性时间比较类排序，但前者对待排序元素的要求较为严格，比如计数排序要求待排序数的最大值不能太大，桶排序要求元素按照hash分桶后桶内元素的数量要均匀。线性时间非比较类排序的典型特点是以空间换时间。 1、冒泡排序（Bubble Sort）冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 1.1 算法描述 比较相邻的元素。如果第一个比第二个大，就交换它们两个； 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数； 针对所有的元素重复以上的步骤，除了最后一个； 重复步骤1~3，直到排序完成。 1.2 动图演示 1.3 代码实现1234567891011121314151617181920212223// 分类 -------------- 内部比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- O(n^2)// 最优时间复杂度 ---- 如果能在内部循环第一次运行时,使用一个旗标来表示有无需要交换的可能,可以把最优时间复杂度降低到O(n)// 平均时间复杂度 ---- O(n^2)// 所需辅助空间 ------ O(1)// 稳定性 ------------ 稳定void BubbleSort(RecordType arr[]) &#123; var len = arr.length; change = TRUE; for (var i = 0; i &lt; len - 1 &amp;&amp; change; i++) &#123; change = FALSE; for (var j = 0; j &lt; len - 1 - i; j++) &#123;// 依次比较相邻的两个元素,使较大的那个向后移 if (arr[j].key &gt; arr[j+1].key) &#123; // 相邻元素两两对比。 如果条件改成arr[j].key &gt;= arr[j+1].key,则变为不稳定的排序算法 var temp = arr[j+1]; // 元素交换 arr[j+1] = arr[j]; arr[j] = temp; change = TRUE; &#125; &#125; &#125; return arr;&#125; ​ 假如说上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行冒泡排序，则实现过程如下： ​ 使用冒泡排序为一列数字进行排序的过程如右图所示: 尽管冒泡排序是最容易了解和实现的排序算法之一，但它对于少数元素之外的数列排序是很没有效率的。 1.1、冒泡排序的改进：鸡尾酒排序（定向/双向冒泡排序）​ 鸡尾酒排序，也叫定向冒泡排序，是冒泡排序的一种改进，即排序过程中交替改变扫描方向。 先从底向上冒一个最小元素，再从上向低冒一个最大元素。 此算法与冒泡排序的不同处在于从低到高然后从高到低，而冒泡排序则仅从低到高去比较序列里的每个元素。他可以得到比冒泡排序稍微好一点的效能。 鸡尾酒排序的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;stdio.h&gt;// 分类 -------------- 内部比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- O(n^2)// 最优时间复杂度 ---- 如果序列在一开始已经大部分排序过的话,会接近O(n)// 平均时间复杂度 ---- O(n^2)// 所需辅助空间 ------ O(1)// 稳定性 ------------ 稳定void Swap(int A[], int i, int j)&#123; int temp = A[i]; A[i] = A[j]; A[j] = temp;&#125;void CocktailSort(int A[], int n)&#123; int left = 0; // 初始化边界 int right = n - 1; bool flag = TRUE; while (flag) &#123; flag = FLASE; for (int i = left; i &lt; right; i++) // 前半轮,从左到右扫描，将最大元素放到最右边 &#123; if (A[i] &gt; A[i + 1]) &#123; Swap(A, i, i + 1); flag = TRUE; &#125; &#125; right--; for (int i = right; i &gt; left; i--) // 后半轮,从右到左扫描,将最小元素放到最左边 &#123; if (A[i - 1] &gt; A[i]) &#123; Swap(A, i - 1, i); flag = TRUE; &#125; &#125; left++; &#125;&#125;int main()&#123; int A[] = &#123; 6, 5, 3, 1, 8, 7, 2, 4 &#125;; // 从小到大定向冒泡排序 int n = sizeof(A) / sizeof(int); CocktailSort(A, n); printf("鸡尾酒排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; ​ 使用鸡尾酒排序为一列数字进行排序的过程如右图所示： 以序列(2,3,4,5,1)为例，鸡尾酒排序只需要访问一次序列就可以完成排序，但如果使用冒泡排序则需要四次。但是在乱数序列的状态下，鸡尾酒排序与冒泡排序的效率都很差劲。 2、选择排序（Selection Sort）选择排序(Selection-sort)是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 2.1 算法描述n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下： 初始状态：无序区为R[1..n]，有序区为空； 第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中-选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区； n-1趟结束，数组有序化了。 2.2 动图演示 2.3 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;stdio.h&gt;// 分类 -------------- 内部比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- O(n^2)// 最优时间复杂度 ---- O(n^2)// 平均时间复杂度 ---- O(n^2)// 所需辅助空间 ------ O(1)// 稳定性 ------------ 不稳定void Swap(int A[], int i, int j)&#123; int temp = A[i]; A[i] = A[j]; A[j] = temp;&#125;void SelectionSort(int A[], int n)&#123; for (int i = 0; i &lt; n - 1; i++) // i为已排序序列的末尾 &#123; int min = i; for (int j = i + 1; j &lt; n; j++) // 未排序序列 &#123; if (A[j] &lt; A[min]) // 找出未排序序列中的最小值 &#123; min = j; &#125; &#125; if (min != i) &#123; Swap(A, min, i); // 放到已排序序列的末尾，该操作很有可能把稳定性打乱，所以选择排序是不稳定的排序算法 &#125; &#125;&#125;int main()&#123; int A[] = &#123; 8, 5, 2, 6, 9, 3, 1, 4, 0, 7 &#125;; // 从小到大选择排序 int n = sizeof(A) / sizeof(int); SelectionSort(A, n); printf("选择排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; 上述代码对序列{ 8, 5, 2, 6, 9, 3, 1, 4, 0, 7 }进行选择排序的实现过程如右图: 使用选择排序为一列数字进行排序的宏观过程： 选择排序是不稳定的排序算法，不稳定发生在最小元素与A[i]交换的时刻。 比如序列：{ 5, 8, 5, 2, 9 }，一次选择的最小元素是2，然后把2和第一个5进行交换，从而改变了两个元素5的相对次序。 3、插入排序（Insertion Sort）​ 插入排序（Insertion-Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。它的工作原理非常类似于我们抓扑克牌 。 ​ 对于未排序数据(右手抓到的牌)，在已排序序列(左手已经排好序的手牌)中从后向前扫描，找到相应位置并插入。 插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 3.1 算法描述一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下： 从第一个元素开始，该元素可以认为已经被排序； 取出下一个元素，在已经排序的元素序列中从后向前扫描； 如果该元素（已排序）大于新元素，将该元素移到下一位置； 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置； 将新元素插入到该位置后； 重复步骤2~5。 3.2 动图演示 3.2 代码实现1234567891011121314151617181920212223242526272829303132333435363738#include &lt;stdio.h&gt;// 分类 ------------- 内部比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- 最坏情况为输入序列是降序排列的,此时时间复杂度O(n^2)// 最优时间复杂度 ---- 最好情况为输入序列是升序排列的,此时时间复杂度O(n)// 平均时间复杂度 ---- O(n^2)// 所需辅助空间 ------ O(1)// 稳定性 ------------ 稳定void InsertionSort(int A[], int n)&#123; for (int i = 1; i &lt; n; i++) // 类似抓扑克牌排序 &#123; int get = A[i]; // 右手抓到一张扑克牌 int j = i - 1; // 拿在左手上的牌总是排序好的 while (j &gt;= 0 &amp;&amp; A[j] &gt; get) // 将抓到的牌与手牌从右向左进行比较 &#123; A[j + 1] = A[j]; // 如果该手牌比抓到的牌大，就将其右移 j--; &#125; A[j + 1] = get; // 直到该手牌比抓到的牌小(或二者相等)，将抓到的牌插入到该手牌右边(相等元素的相对次序未变，所以插入排序是稳定的) &#125;&#125;int main()&#123; int A[] = &#123; 6, 5, 3, 1, 8, 7, 2, 4 &#125;;// 从小到大插入排序 int n = sizeof(A) / sizeof(int); InsertionSort(A, n); printf("插入排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; 上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行插入排序的实现过程如下 使用插入排序为一列数字进行排序的宏观过程： 插入排序不适合对于数据量比较大的排序应用。但是，如果需要排序的数据量很小，比如量级小于千，那么插入排序还是一个不错的选择。 插入排序在工业级库中也有着广泛的应用，在STL的sort算法和stdlib的qsort算法中，都将插入排序作为快速排序的补充，用于少量元素的排序（通常为8个或以下）。 3.1、插入排序的改进：二分插入排序​ 对于插入排序，如果比较操作的代价比交换操作大的话，可以采用二分查找法来减少比较操作的次数，我们称为二分插入排序，代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;stdio.h&gt;// 分类 -------------- 内部比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- O(n^2)// 最优时间复杂度 ---- O(nlogn)// 平均时间复杂度 ---- O(n^2)// 所需辅助空间 ------ O(1)// 稳定性 ------------ 稳定void InsertionSortDichotomy(int A[], int n)&#123; for (int i = 1; i &lt; n; i++) &#123; int get = A[i]; // 右手抓到一张扑克牌 int left = 0; // 拿在左手上的牌总是排序好的，所以可以用二分法 int right = i - 1; // 手牌左右边界进行初始化 while (left &lt;= right) // 采用二分法定位新牌的位置 &#123; int mid = (left + right) / 2; if (A[mid] &gt; get) right = mid - 1; else left = mid + 1; &#125; for (int j = i - 1; j &gt;= left; j--) // 将欲插入新牌位置右边的牌整体向右移动一个单位 &#123; A[j + 1] = A[j]; &#125; A[left] = get; // 将抓到的牌插入手牌 &#125;&#125;int main()&#123; int A[] = &#123; 5, 2, 9, 4, 7, 6, 1, 3, 8 &#125;;// 从小到大二分插入排序 int n = sizeof(A) / sizeof(int); InsertionSortDichotomy(A, n); printf("二分插入排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; 当n较大时，二分插入排序的比较次数比直接插入排序的最差情况好得多，但比直接插入排序的最好情况要差，所当以元素初始序列已经接近升序时，直接插入排序比二分插入排序比较次数少。二分插入排序元素移动次数与直接插入排序相同，依赖于元素初始序列。 4、希尔排序（Shell Sort）-插入排序的更高效改进​ 1959年Shell发明，第一个突破O(n2)的排序算法，是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫递减增量排序。希尔排序是不稳定的排序算法。 ​ 希尔排序是基于插入排序的以下两点性质而提出改进方法的： 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位 4.1 算法描述先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述： 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 4.2 动图演示 4.3 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;stdio.h&gt; // 分类 -------------- 内部比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- 根据步长序列的不同而不同。已知最好的为O(n(logn)^2)// 最优时间复杂度 ---- O(n)// 平均时间复杂度 ---- 根据步长序列的不同而不同。// 所需辅助空间 ------ O(1)// 稳定性 ------------ 不稳定void ShellSort(int A[], int n)&#123; int h = 0; while (h &lt;= n) // 生成初始增量 &#123; h = 3 * h + 1; &#125; while (h &gt;= 1) &#123; for (int i = h; i &lt; n; i++) &#123; int j = i - h; int get = A[i]; while (j &gt;= 0 &amp;&amp; A[j] &gt; get) &#123; A[j + h] = A[j]; j = j - h; &#125; A[j + h] = get; &#125; h = (h - 1) / 3; // 递减增量 &#125;&#125;int main()&#123; int A[] = &#123; 5, 2, 9, 4, 7, 6, 1, 3, 8 &#125;;// 从小到大希尔排序 int n = sizeof(A) / sizeof(int); ShellSort(A, n); printf("希尔排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; 4.4 算法分析以23, 10, 4, 1的步长序列进行希尔排序： 希尔排序是不稳定的排序算法，虽然一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱。 比如序列：{ 3, 5, 10, 8, 7, 2, 8, 1, 20, 6 }，h=2时分成两个子序列 { 3, 10, 7, 8, 20 } 和 { 5, 8, 2, 1, 6 } ，未排序之前第二个子序列中的8在前面，现在对两个子序列进行插入排序，得到 { 3, 7, 8, 10, 20 } 和 { 1, 2, 5, 6, 8 } ，即 { 3, 1, 7, 2, 8, 5, 10, 6, 20, 8 } ，两个8的相对次序发生了改变。 ​ 希尔排序的核心在于间隔序列的设定。既可以提前设定好间隔序列，也可以动态的定义间隔序列。动态定义间隔序列的算法是《算法（第4版）》的合著者Robert Sedgewick提出的。 5、归并排序（Merge Sort）​ 归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 5.1 算法描述​ 归并排序的实现分为递归实现与非递归(迭代)实现。递归实现的归并排序是算法设计中分治策略的典型应用，我们将一个大问题分割成小问题分别解决，然后用所有小问题的答案来解决整个大问题。非递归(迭代)实现的归并排序首先进行是两两归并，然后四四归并，然后是八八归并，一直下去直到归并了整个数组。 归并排序算法主要依赖归并(Merge)操作。归并操作指的是将两个已经排序的序列合并成一个序列的操作，归并操作步骤如下： 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列 设定两个指针，最初位置分别为两个已经排序序列的起始位置 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置 重复步骤3直到某一指针到达序列尾 将另一序列剩下的所有元素直接复制到合并序列尾 5.2 动图演示 5.3 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &lt;stdio.h&gt;#include &lt;limits.h&gt;// 分类 -------------- 内部比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- O(nlogn)// 最优时间复杂度 ---- O(nlogn)// 平均时间复杂度 ---- O(nlogn)// 所需辅助空间 ------ O(n)// 稳定性 ------------ 稳定void Merge(int A[], int left, int mid, int right)// 合并两个已排好序的数组A[left...mid]和A[mid+1...right]&#123; int len = right - left + 1; int *temp = new int[len]; // 辅助空间O(n) int index = 0; int i = left; // 前一数组的起始元素 int j = mid + 1; // 后一数组的起始元素 while (i &lt;= mid &amp;&amp; j &lt;= right) &#123; temp[index++] = A[i] &lt;= A[j] ? A[i++] : A[j++]; // 带等号保证归并排序的稳定性 &#125; while (i &lt;= mid) &#123; temp[index++] = A[i++]; &#125; while (j &lt;= right) &#123; temp[index++] = A[j++]; &#125; for (int k = 0; k &lt; len; k++) &#123; A[left++] = temp[k]; &#125;&#125;void MergeSortRecursion(int A[], int left, int right) // 递归实现的归并排序(自顶向下)&#123; if (left == right) // 当待排序的序列长度为1时，递归开始回溯，进行merge操作 return; int mid = (left + right) / 2; MergeSortRecursion(A, left, mid); MergeSortRecursion(A, mid + 1, right); Merge(A, left, mid, right);&#125;void MergeSortIteration(int A[], int len) // 非递归(迭代)实现的归并排序(自底向上)&#123; int left, mid, right;// 子数组索引,前一个为A[left...mid]，后一个子数组为A[mid+1...right] for (int i = 1; i &lt; len; i *= 2) // 子数组的大小i初始为1，每轮翻倍 &#123; left = 0; while (left + i &lt; len) // 后一个子数组存在(需要归并) &#123; mid = left + i - 1; right = mid + i &lt; len ? mid + i : len - 1;// 后一个子数组大小可能不够 Merge(A, left, mid, right); left = right + 1; // 前一个子数组索引向后移动 &#125; &#125;&#125;int main()&#123; int A1[] = &#123; 6, 5, 3, 1, 8, 7, 2, 4 &#125;; // 从小到大归并排序 int A2[] = &#123; 6, 5, 3, 1, 8, 7, 2, 4 &#125;; int n1 = sizeof(A1) / sizeof(int); int n2 = sizeof(A2) / sizeof(int); MergeSortRecursion(A1, 0, n1 - 1); // 递归实现 MergeSortIteration(A2, n2); // 非递归实现 printf("递归实现的归并排序结果："); for (int i = 0; i &lt; n1; i++) &#123; printf("%d ", A1[i]); &#125; printf("\n"); printf("非递归实现的归并排序结果："); for (int i = 0; i &lt; n2; i++) &#123; printf("%d ", A2[i]); &#125; printf("\n"); return 0;&#125; 上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行归并排序的实例如下 使用归并排序为一列数字进行排序的宏观过程： 归并排序除了可以对数组进行排序，还可以高效的求出数组小和（即单调和）以及数组中的逆序对。 5.4 算法分析归并排序是一种稳定的排序方法。和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是O(nlogn）的时间复杂度。代价是需要额外的内存空间。 6、快速排序（Quick Sort）​ 快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。 6.1 算法描述​ 选择一个基准，小于放左边，大于放右边。 快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下： 从数列中挑出一个元素，称为 “基准”（pivot）； 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。 6.2 动图演示 ​ 上图是每次将基准交换。 ​ 或者如下，最后再将基准交换。 ​ 方法其实很简单：分别从初始序列“6 1 2 7 9 3 4 5 10 8”两端开始“探测”。先从右往左找一个小于6的数，再从左往右找一个大于6的数，然后交换他们。这里可以用两个变量i和j，分别指向序列最左边和最右边。我们为这两个变量起个好听的名字“哨兵i”和“哨兵j”。刚开始的时候让哨兵i指向序列的最左边（即i=1），指向数字6。让哨兵j指向序列的最右边（即=10），指向数字。 ​ 首先哨兵j开始出动。因为此处设置的基准数是最左边的数，所以需要让哨兵j先出动，这一点非常重要（请自己想一想为什么）。哨兵j一步一步地向左挪动（即j–），直到找到一个小于6的数停下来。接下来哨兵i再一步一步向右挪动（即i++），直到找到一个数大于6的数停下来。最后哨兵j停在了数字5面前，哨兵i停在了数字7面前。 ​ 现在交换哨兵i和哨兵j所指向的元素的值。交换之后的序列如下： ​ 6 1 2 5 9 3 4 7 10 8 ​ 到此，第一次交换结束。接下来开始哨兵j继续向左挪动（再友情提醒，每次必须是哨兵j先出发）。他发现了4（比基准数6要小，满足要求）之后停了下来。哨兵i也继续向右挪动的，他发现了9（比基准数6要大，满足要求）之后停了下来。此时再次进行交换，交换之后的序列如下： 6 1 2 5 4 3 9 7 10 8 ​ 第二次交换结束，“探测”继续。哨兵j继续向左挪动，他发现了3（比基准数6要小，满足要求）之后又停了下来。哨兵i继续向右移动，糟啦！此时哨兵i和哨兵j相遇了，哨兵i和哨兵j都走到3面前。说明此时“探测”结束。我们将基准数6和3进行交换。交换之后的序列如下： 3 1 2 5 4 6 9 7 10 8 ​ 到此第一轮“探测”真正结束。此时以基准数6为分界点，6左边的数都小于等于6，6右边的数都大于等于6。回顾一下刚才的过程，其实哨兵j的使命就是要找小于基准数的数，而哨兵i的使命就是要找大于基准数的数，直到i和j碰头为止。 注：最好的是设置一个临时变量，做覆盖操作而不是一直做交换操作。 6.3 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;stdio.h&gt;// 分类 ------------ 内部比较排序// 数据结构 --------- 数组// 最差时间复杂度 ---- 每次选取的基准都是最大（或最小）的元素，导致每次只划分出了一个分区，需要进行n-1次划分才能结束递归，时间复杂度为O(n^2)// 最优时间复杂度 ---- 每次选取的基准都是中位数，这样每次都均匀的划分出两个分区，只需要logn次划分就能结束递归，时间复杂度为O(nlogn)// 平均时间复杂度 ---- O(nlogn)// 所需辅助空间 ------ 主要是递归造成的栈空间的使用(用来保存left和right等局部变量)，取决于递归树的深度，一般为O(logn)，最差为O(n) // 稳定性 ---------- 不稳定void Swap(int A[], int i, int j)&#123; int temp = A[i]; A[i] = A[j]; A[j] = temp;&#125;int Partition(int A[], int left, int right) // 划分函数&#123; int pivot = A[right]; // 这里每次都选择最后一个元素作为基准 int tail = left - 1; // tail为小于基准的子数组最后一个元素的索引 for (int i = left; i &lt; right; i++) // 遍历基准以外的其他元素 &#123; if (A[i] &lt;= pivot) // 把小于等于基准的元素放到前一个子数组末尾 &#123; Swap(A, ++tail, i); &#125; &#125; Swap(A, tail + 1, right); // 最后把基准放到前一个子数组的后边，剩下的子数组既是大于基准的子数组 // 该操作很有可能把后面元素的稳定性打乱，所以快速排序是不稳定的排序算法 return tail + 1; // 返回基准的索引&#125;void QuickSort(int A[], int left, int right)&#123; if (left &gt;= right) return; int pivot_index = Partition(A, left, right); // 基准的索引 QuickSort(A, left, pivot_index - 1); QuickSort(A, pivot_index + 1, right);&#125;int main()&#123; int A[] = &#123; 5, 2, 9, 4, 7, 6, 1, 3, 8 &#125;; // 从小到大快速排序 int n = sizeof(A) / sizeof(int); QuickSort(A, 0, n - 1); printf("快速排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; 使用快速排序法对一列数字进行排序的过程： 快速排序是不稳定的排序算法，不稳定发生在基准元素与A[tail+1]交换的时刻。 比如序列：{ 1, 3, 4, 2, 8, 9, 8, 7, 5 }，基准元素是5，一次划分操作后5要和第一个8进行交换，从而改变了两个元素8的相对次序。 Java系统提供的Arrays.sort函数。对于基础类型，底层使用快速排序。对于非基础类型，底层使用归并排序。请问是为什么？ 答：这是考虑到排序算法的稳定性。对于基础类型，相同值是无差别的，排序前后相同值的相对位置并不重要，所以选择更为高效的快速排序，尽管它是不稳定的排序算法；而对于非基础类型，排序前后相等实例的相对位置不宜改变，所以选择稳定的归并排序。 7、堆排序（Heap Sort）​ 堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 7.1 算法描述 将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区； 将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&lt;=R[n]； 由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。 7.2 动图演示 构建初始堆 整体排序流程 7.3 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;stdio.h&gt;// 分类 -------------- 内部比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- O(nlogn)// 最优时间复杂度 ---- O(nlogn)// 平均时间复杂度 ---- O(nlogn)// 所需辅助空间 ------ O(1)// 稳定性 ------------ 不稳定void Swap(int A[], int i, int j)&#123; int temp = A[i]; A[i] = A[j]; A[j] = temp;&#125;void Heapify(int A[], int i, int size) // 从A[i]向下进行堆调整&#123; int left_child = 2 * i + 1; // 左孩子索引 int right_child = 2 * i + 2; // 右孩子索引 int max = i; // 选出当前结点与其左右孩子三者之中的最大值 if (left_child &lt; size &amp;&amp; A[left_child] &gt; A[max]) max = left_child; if (right_child &lt; size &amp;&amp; A[right_child] &gt; A[max]) max = right_child; if (max != i) &#123; Swap(A, i, max); // 把当前结点和它的最大(直接)子节点进行交换 Heapify(A, max, size); // 递归调用，继续从当前结点向下进行堆调整 &#125;&#125;int BuildHeap(int A[], int n) // 建堆，时间复杂度O(n)&#123; int heap_size = n; for (int i = heap_size / 2 - 1; i &gt;= 0; i--) // 从每一个非叶结点开始向下进行堆调整 Heapify(A, i, heap_size); return heap_size;&#125;void HeapSort(int A[], int n)&#123; int heap_size = BuildHeap(A, n); // 建立一个最大堆 while (heap_size &gt; 1) // 堆（无序区）元素个数大于1，未完成排序 &#123; // 将堆顶元素与堆的最后一个元素互换，并从堆中去掉最后一个元素 // 此处交换操作很有可能把后面元素的稳定性打乱，所以堆排序是不稳定的排序算法 Swap(A, 0, --heap_size); Heapify(A, 0, heap_size); // 从新的堆顶元素开始向下进行堆调整，时间复杂度O(logn) &#125;&#125;int main()&#123; int A[] = &#123; 5, 2, 9, 4, 7, 6, 1, 3, 8 &#125;;// 从小到大堆排序 int n = sizeof(A) / sizeof(int); HeapSort(A, n); printf("堆排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; 堆排序算法的演示： 动画中在排序过程之前简单的表现了创建堆的过程以及堆的逻辑结构。 堆排序是不稳定的排序算法，不稳定发生在堆顶元素与A[i]交换的时刻。 比如序列：{ 9, 5, 7, 5 }，堆顶元素是9，堆排序下一步将9和第二个5进行交换，得到序列 { 5, 5, 7, 9 }，再进行堆调整得到{ 7, 5, 5, 9 }，重复之前的操作最后得到{ 5, 5, 7, 9 }从而改变了两个5的相对次序。 以上为比较排序。 以下为非比较排序。 8、计数排序（Counting Sort）​ 计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 ​ 通俗地理解，例如有10个年龄不同的人，假如统计出有8个人的年龄不比小明大（即小于等于小明的年龄，这里也包括了小明），那么小明的年龄就排在第8位，通过这种思想可以确定每个人的位置，也就排好了序。当然，年龄一样时需要特殊处理（保证稳定性）：通过反向填充目标数组，填充完毕后将对应的数字统计递减，可以确保计数排序的稳定性。 8.1 算法描述 找出待排序的数组中最大和最小的元素； 统计数组中每个值为i的元素出现的次数，存入数组C的第i项； 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）； 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。 8.2 动图演示12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include&lt;iostream&gt;using namespace std;// 分类 ------------ 内部非比较排序// 数据结构 --------- 数组// 最差时间复杂度 ---- O(n + k)// 最优时间复杂度 ---- O(n + k)// 平均时间复杂度 ---- O(n + k)// 所需辅助空间 ------ O(n + k)// 稳定性 ----------- 稳定const int k = 100; // 基数为100，排序[0,99]内的整数int C[k]; // 计数数组void CountingSort(int A[], int n)&#123; for (int i = 0; i &lt; k; i++) // 初始化，将数组C中的元素置0(此步骤可省略，整型数组元素默认值为0) &#123; C[i] = 0; &#125; for (int i = 0; i &lt; n; i++) // 使C[i]保存着等于i的元素个数 &#123; C[A[i]]++; &#125; for (int i = 1; i &lt; k; i++) // 使C[i]保存着小于等于i的元素个数，排序后元素i就放在第C[i]个输出位置上 &#123; C[i] = C[i] + C[i - 1]; &#125; int *B = (int *)malloc((n) * sizeof(int));// 分配临时空间,长度为n，用来暂存中间数据 for (int i = n - 1; i &gt;= 0; i--) // 从后向前扫描保证计数排序的稳定性(重复元素相对次序不变) &#123; B[--C[A[i]]] = A[i]; // 把每个元素A[i]放到它在输出数组B中的正确位置上 // 当再遇到重复元素时会被放在当前元素的前一个位置上保证计数排序的稳定性 &#125; for (int i = 0; i &lt; n; i++) // 把临时空间B中的数据拷贝回A &#123; A[i] = B[i]; &#125; free(B); // 释放临时空间 &#125;int main()&#123; int A[] = &#123; 15, 22, 19, 46, 27, 73, 1, 19, 8 &#125;; // 针对计数排序设计的输入，每一个元素都在[0,100]上且有重复元素 int n = sizeof(A) / sizeof(int); CountingSort(A, n); printf("计数排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; ​ 计数排序的时间复杂度和空间复杂度与数组A的数据范围（A中元素的最大值与最小值的差加上1）有关，因此对于数据范围很大的数组，计数排序需要大量时间和内存。 例如：对0到99之间的数字进行排序，计数排序是最好的算法，然而计数排序并不适合按字母顺序排序人名，将计数排序用在基数排序算法中，能够更有效的排序数据范围很大的数组。 8.4 算法分析​ 计数排序是一个稳定的排序算法。当输入的元素是 n 个 0到 k 之间的整数时，时间复杂度是O(n+k)，空间复杂度也是O(n+k)，其排序速度快于任何比较排序算法。当k不是很大并且序列比较集中时，计数排序是一个很有效的排序算法。 9、桶排序（Bucket Sort）​ 桶排序也叫箱排序。桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：将数组元素映射到有限数量个桶里，利用计数排序可以定位桶的边界，每个桶再各自进行桶内排序（使用其它排序算法或以递归方式继续使用桶排序）。 9.1 算法描述 设置一个定量的数组当作空桶； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序； 从不是空的桶里把排好序的数据拼接起来。 9.2 图片演示 9.3 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include&lt;iostream&gt;using namespace std;// 分类 ------------- 内部非比较排序// 数据结构 --------- 数组// 最差时间复杂度 ---- O(nlogn)或O(n^2)，只有一个桶，取决于桶内排序方式// 最优时间复杂度 ---- O(n)，每个元素占一个桶// 平均时间复杂度 ---- O(n)，保证各个桶内元素个数均匀即可// 所需辅助空间 ------ O(n + bn)// 稳定性 ----------- 稳定/* 本程序用数组模拟桶 */const int bn = 5; // 这里排序[0,49]的元素，使用5个桶就够了，也可以根据输入动态确定桶的数量int C[bn]; // 计数数组，存放桶的边界信息void InsertionSort(int A[], int left, int right)&#123; for (int i = left + 1; i &lt;= right; i++) // 从第二张牌开始抓，直到最后一张牌 &#123; int get = A[i]; int j = i - 1; while (j &gt;= left &amp;&amp; A[j] &gt; get) &#123; A[j + 1] = A[j]; j--; &#125; A[j + 1] = get; &#125;&#125;int MapToBucket(int x)&#123; return x / 10; // 映射函数f(x)，作用相当于快排中的Partition，把大量数据分割成基本有序的数据块&#125;void CountingSort(int A[], int n)&#123; for (int i = 0; i &lt; bn; i++) &#123; C[i] = 0; &#125; for (int i = 0; i &lt; n; i++) // 使C[i]保存着i号桶中元素的个数 &#123; C[MapToBucket(A[i])]++; &#125; for (int i = 1; i &lt; bn; i++) // 定位桶边界：初始时，C[i]-1为i号桶最后一个元素的位置 &#123; C[i] = C[i] + C[i - 1]; &#125; int *B = (int *)malloc((n) * sizeof(int)); for (int i = n - 1; i &gt;= 0; i--)// 从后向前扫描保证计数排序的稳定性(重复元素相对次序不变) &#123; int b = MapToBucket(A[i]); // 元素A[i]位于b号桶 B[--C[b]] = A[i]; // 把每个元素A[i]放到它在输出数组B中的正确位置上 // 桶的边界被更新：C[b]为b号桶第一个元素的位置 &#125; for (int i = 0; i &lt; n; i++) &#123; A[i] = B[i]; &#125; free(B);&#125;void BucketSort(int A[], int n)&#123; CountingSort(A, n); // 利用计数排序确定各个桶的边界（分桶） for (int i = 0; i &lt; bn; i++) // 对每一个桶中的元素应用插入排序 &#123; int left = C[i]; // C[i]为i号桶第一个元素的位置 int right = (i == bn - 1 ? n - 1 : C[i + 1] - 1);// C[i+1]-1为i号桶最后一个元素的位置 if (left &lt; right) // 对元素个数大于1的桶进行桶内插入排序 InsertionSort(A, left, right); &#125;&#125;int main()&#123; int A[] = &#123; 29, 25, 3, 49, 9, 37, 21, 43 &#125;;// 针对桶排序设计的输入 int n = sizeof(A) / sizeof(int); BucketSort(A, n); printf("桶排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; 下图给出了对{ 29, 25, 3, 49, 9, 37, 21, 43 }进行桶排序的简单演示过程 。 ​ 桶排序不是比较排序，不受到O(nlogn)下限的影响，它是鸽巢排序的一种归纳结果，当所要排序的数组值分散均匀的时候，桶排序拥有线性的时间复杂度。 9.4 算法分析​ 桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 10、基数排序（Radix Sort）​ 基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序。最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。 10.1 算法描述 取得数组中的最大数，并取得位数； arr为原始数组，从最低位开始取每个位组成radix数组； 对radix进行计数排序（利用计数排序适用于小范围数的特点）； 10.2 动图演示 10.3 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include&lt;iostream&gt;using namespace std;// 分类 ------------- 内部非比较排序// 数据结构 ---------- 数组// 最差时间复杂度 ---- O(n * dn)// 最优时间复杂度 ---- O(n * dn)// 平均时间复杂度 ---- O(n * dn)// 所需辅助空间 ------ O(n * dn)// 稳定性 ----------- 稳定const int dn = 3; // 待排序的元素为三位数及以下const int k = 10; // 基数为10，每一位的数字都是[0,9]内的整数int C[k];int GetDigit(int x, int d) // 获得元素x的第d位数字&#123; int radix[] = &#123; 1, 1, 10, 100 &#125;;// 最大为三位数，所以这里只要到百位就满足了 return (x / radix[d]) % 10;&#125;void CountingSort(int A[], int n, int d)// 依据元素的第d位数字，对A数组进行计数排序&#123; for (int i = 0; i &lt; k; i++) &#123; C[i] = 0; &#125; for (int i = 0; i &lt; n; i++) &#123; C[GetDigit(A[i], d)]++; &#125; for (int i = 1; i &lt; k; i++) &#123; C[i] = C[i] + C[i - 1]; &#125; int *B = (int*)malloc(n * sizeof(int)); for (int i = n - 1; i &gt;= 0; i--) &#123; int dight = GetDigit(A[i], d); // 元素A[i]当前位数字为dight B[--C[dight]] = A[i]; // 根据当前位数字，把每个元素A[i]放到它在输出数组B中的正确位置上 // 当再遇到当前位数字同为dight的元素时，会将其放在当前元素的前一个位置上保证计数排序的稳定性 &#125; for (int i = 0; i &lt; n; i++) &#123; A[i] = B[i]; &#125; free(B);&#125;void LsdRadixSort(int A[], int n) // 最低位优先基数排序&#123; for (int d = 1; d &lt;= dn; d++) // 从低位到高位 CountingSort(A, n, d); // 依据第d位数字对A进行计数排序&#125;int main()&#123; int A[] = &#123; 20, 90, 64, 289, 998, 365, 852, 123, 789, 456 &#125;;// 针对基数排序设计的输入 int n = sizeof(A) / sizeof(int); LsdRadixSort(A, n); printf("基数排序结果："); for (int i = 0; i &lt; n; i++) &#123; printf("%d ", A[i]); &#125; printf("\n"); return 0;&#125; 下图给出了对{ 329, 457, 657, 839, 436, 720, 355 }进行基数排序的简单演示过程 ​ 基数排序的时间复杂度是O(n * dn)，其中n是待排序元素个数，dn是数字位数。这个时间复杂度不一定优于O(n log n)，dn的大小取决于数字位的选择（比如比特位数），和待排序数据所属数据类型的全集的大小；dn决定了进行多少轮处理，而n是每轮处理的操作数目。 如果考虑和比较排序进行对照，基数排序的形式复杂度虽然不一定更小，但由于不进行比较，因此其基本操作的代价较小，而且如果适当的选择基数，dn一般不大于log n，所以基数排序一般要快过基于比较的排序，比如快速排序。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序并不是只能用于整数排序。 10.4 算法分析​ 基数排序基于分别排序，分别收集，所以是稳定的。但基数排序的性能比桶排序要略差，每一次关键字的桶分配都需要O(n)的时间复杂度，而且分配之后得到新的关键字序列又需要O(n)的时间复杂度。假如待排数据可以分为d个关键字，则基数排序的时间复杂度将是O(d*2n) ，当然d要远远小于n，因此基本上还是线性级别的。 ​ 基数排序的空间复杂度为O(n+k)，其中k为桶的数量。一般来说n&gt;&gt;k，因此额外空间需要大概n个左右。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序算法</tag>
        <tag>排序</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指Offer（一）：二维数组中的查找]]></title>
    <url>%2F2018%2F07%2F12%2F%E5%89%91%E6%8C%87Offer%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[剑指Offer（一）：二维数组中的查找摘要 在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 一、前言本系列文章为《剑指offer》刷题笔记。 刷题平台：牛客网 二、题目在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 1、思路​ 首先选取数组中右上角的数字。如果该数字等于要查找的数字，查找过程结束；如果该数字大于要查找的数组，剔除这个数字所在的列；如果该数字小于要查找的数字，剔除这个数字所在的行。也就是说如果要查找的数字不在数组的右上角，则每一次都在数组的查找范围中剔除一行或者一列，这样每一步都可以缩小查找的范围，直到找到要查找的数字，或者查找范围为空。 2、举例如果在一个二维数组中找到数字7，则返回true，如果没有找到，则返回false。 查找过程如下： 3、编程实现C++： 1234567891011121314151617181920212223class Solution &#123;public: bool Find(int target, vector&lt;vector&lt;int&gt; &gt; array) &#123; int rows = array.size(); int cols = array[0].size(); if(!array.empty() &amp;&amp; rows &gt; 0 &amp;&amp; cols &gt; 0)&#123; int row = 0; int col = cols - 1; while(row &lt; rows &amp;&amp; col &gt;= 0)&#123; if(array[row][col] == target)&#123; return true; &#125; else if(array[row][col] &gt; target)&#123; --col; &#125; else&#123; ++row; &#125; &#125; &#125; return false; &#125;&#125;; Python2.7： 12345678910111213141516171819# -*- coding:utf-8 -*-class Solution: # array 二维列表 def Find(self, target, array): # write code here rows = len(array) cols = len(array[0]) if rows &gt; 0 and cols &gt; 0: row = 0 col = cols - 1 while row &lt; rows and col &gt;= 0: if target == array[row][col]: return True elif target &lt; array[row][col]: col -= 1 else: row += 1 return False]]></content>
      <categories>
        <category>剑指Offer</category>
      </categories>
      <tags>
        <tag>剑指Offer</tag>
        <tag>数组</tag>
        <tag>笔试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解朴素贝叶斯]]></title>
    <url>%2F2018%2F07%2F06%2F%E7%90%86%E8%A7%A3%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
    <content type="text"><![CDATA[理解朴素贝叶斯（1）先验概率、后验概率、联合概率、全概率如果我对这个西瓜没有任何了解，包括瓜的颜色、形状、瓜蒂是否脱落。按常理来说，西瓜成熟的概率大概是 60%。那么，这个概率 P(瓜熟) 就被称为先验概率。 即，先验概率是根据以往经验和分析得到的概率，先验概率无需样本数据，不受任何条件的影响。就像只根据常识而不根据西瓜状态来判断西瓜是否熟，这就是先验概率。 一个判断西瓜是否成熟的常识，就是看瓜蒂是否脱落。一般来说，瓜蒂脱落的情况下，西瓜成熟的概率大一些，大概是 75%。如果把瓜蒂脱落当作一种结果，然后去推测西瓜成熟的概率，这个概率 P(瓜熟 | 瓜蒂脱落) 就被称为后验概率。后验概率类似于条件概率。 知道了先验概率和后验概率，我们再来看看什么是联合概率。P(瓜熟，瓜蒂脱落) 称之为联合分布，它表示瓜熟了且瓜蒂脱落的概率。关于联合概率，满足下列乘法等式： P(瓜熟，瓜蒂脱落) = P(瓜熟**|瓜蒂脱落)**·P(瓜蒂脱落)=P(瓜蒂脱落|瓜熟)·P(瓜熟) 其中，P(瓜熟 | 瓜蒂脱落) 就是刚刚介绍的后验概率，表示在“瓜蒂脱落”的条件下，“瓜熟”的概率。P(瓜蒂脱落 | 瓜熟) 表示在“瓜熟”的情况下，“瓜蒂脱落”的概率。 如何计算瓜蒂脱落的概率呢？实际上可以分成两种情况：一种是瓜熟状态下瓜蒂脱落的概率，另一种是瓜生状态下瓜蒂脱落的概率。瓜蒂脱落的概率就是这两种情况之和。因此，我们就推导出了全概率公式： P(瓜蒂脱落)=P(瓜蒂脱落|瓜熟)·P(瓜熟)+P(瓜蒂脱落|瓜生)·P(瓜生) （2）单个特征判断瓜熟好了，介绍完先验概率、后验概率、联合概率、全概率后，我们来看这样一个问题：西瓜的状态分成两种：瓜熟与瓜生，概率分别为 0.6 与 0.4，且瓜熟里面瓜蒂脱落的概率是 0.8，瓜生里面瓜蒂脱落的概率是 0.4。那么，如果我现在挑到了一个瓜蒂脱落的瓜，则该瓜是好瓜的概率多大？ 显然，这是一个计算后验概率的问题，根据我们上面推导的联合概率和全概率公式，可以求出： 一项一项来看： 条件概率 P(瓜蒂脱落 | 瓜熟) = 0.8 先验概率 P(瓜熟) = 0.6 条件概率 P(瓜蒂脱落 | 瓜生) = 0.4 先验概率 P(瓜生) = 0.4 将以上数值带入上式，得： 注意，以上这种计算后验概率的公式就是利用贝叶斯定理。 （3）多个特征判断瓜熟判断一个瓜是否熟了，除了要看瓜蒂是否脱落，还要看瓜的形状和颜色。形状有圆和尖之分，颜色有深绿、浅绿、青色之分。我们可以使用刚刚引入的贝叶斯定理思想来尝试解决这个问题。 现在，特征由原来的 1 个，变成现在的 3 个，我们用 X 表示特征，用 Y 表示瓜的类型（瓜熟还是瓜生）。则根据贝叶斯定理，后验概率 P(Y=ck | X=x) 的表达式为： 其中，ck 表示类别，k 为类别个数。本例中，k = 1，2，c1 表示瓜熟，c2 表示瓜生。上面的公式看似有点复杂，但其实与上一节单特征（瓜蒂是否脱落）的形式是一致的。 有一点需要注意，这里的特征 X 不再是单一的，而是包含了 3 个特征。因此，条件概率 P(X=x | Y=ck) 假设各个条件相互独立，也就是说假设不同特征之间是相互独立的。这样，P(X=x | Y=ck) 就可以写成： 其中，n 为特征个数，j 表示当前所属特征。针对这个例子，P(X=x | Y=ck) 可以写成： 这种条件独立性的假设就是朴素贝叶斯法“朴素”二字的由来。这一假设让朴素贝叶斯法变得简单，但是有时候会牺牲一定的分类准确率。 ​ 利用朴素贝叶斯思想，我们就可以把后验概率写成： 上面的公式看上去比较复杂，其实只是样本特征增加了，形式上与上一节 P(瓜熟 | 瓜蒂脱落) 是一致的。 现在，一个西瓜，观察了它的瓜蒂、形状、颜色三个特征，就能根据上面的朴素贝叶斯公式，分别计算 c1（瓜熟）和 c2（瓜生）的概率，即 P(Y=c1 | X=x) 和 P(Y=c2 | X=x)。然后再比较 P(Y=c1 | X=x) 和 P(Y=c2 | X=x) 值的大小： 若 P(Y=c1 | X=x) &gt; P(Y=c2 | X=x)，则判断瓜熟； 若 P(Y=c1 | X=x) &lt; P(Y=c2 | X=x)，则判断瓜生。 值得注意的是上式中的分母部分，对于所有的 ck 来说，都是一样的。因此，分母可以省略，不同的 ck，仅比较 P(Y=ck | X=x) 的分子即可： （2）朴素贝叶斯分类买瓜之前，还有一件事情要做，就是搜集样本数据。通过网上资料和查阅，获得了一组包含 10 组样本的数据。这组数据是不同瓜蒂、形状、颜色对应的西瓜是生是熟。我把这组数据当成是历史经验数据，以它为标准。 其中，瓜蒂分为脱落和未脱，形状分为圆形和尖形，颜色分为深绿、浅绿、青色。不同特征组合对应着瓜熟或者瓜生。 现在，挑了一个西瓜，它的瓜蒂脱落、形状圆形、颜色青色。这时候，就完全可以根据样本数据和朴素贝叶斯法来计算后验概率。 首先，对于瓜熟的情况： 瓜熟的先验概率： P(瓜熟) = 6 / 10 = 0.6。 条件概率： P(脱落 | 瓜熟) = 4 / 6 = 2 / 3。 条件概率： P(圆形 | 瓜熟) = 4 / 6 = 2 / 3。 条件概率： P(青色 | 瓜熟) = 2 / 6 = 1 / 3。 计算后验概率分子部分：P(瓜熟) × P(脱落 | 瓜熟) × P(圆形 | 瓜熟) × P(青色 | 瓜熟) = 0.6 × (2 / 3) × (2 / 3) × (1 / 3) = 4 / 45。 然后，对于瓜生的情况： 瓜生的先验概率： P(瓜生) = 4 / 10 = 0.4。 条件概率： P(脱落 | 瓜生) = 1 / 4 = 0.25。 条件概率： P(圆形 | 瓜生) = 1 / 4 = 0.25。 条件概率： P(青色 | 瓜生) = 1 / 4 = 0.25。 计算后验概率分子部分：P(瓜生) × P(脱落 | 瓜生) × P(圆形 | 瓜生) × P(青色 | 瓜生) = 0.4 × 0.25 × 0.25 × 0.25 = 1 / 160。 因为 4 / 45 &gt; 1 / 160，所以预测为瓜熟。终于计算完了，很肯定这个西瓜瓜蒂脱落、形状圆形、颜色青色，应该是熟瓜。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>朴素贝叶斯</tag>
        <tag>西瓜书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[域名解析]]></title>
    <url>%2F2018%2F07%2F03%2F%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[域名解析域名有钱最好买.com的，不要买.cn的，我自己买的.cn的好多坑，.top的相对就比较便宜（low）。 此次在腾讯云买的dadavision.cn。 之前.cn的一直要我备案，否则DNS解析不了，而且还证书审核失败。 在github项目的setting里面设置域名 添加域名解析 这里注意 在添加绑定域名后需要注意以下问题（未绑定可以不用） 需要将github上CNAME里面内容在文件工程中GitBlog\source\CNAME 这里注意新建的CNAME不要有后缀名。]]></content>
      <categories>
        <category>域名解析</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
        <tag>next</tag>
        <tag>教程</tag>
        <tag>域名</tag>
        <tag>域名解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch0.4.0升级概述新手教程]]></title>
    <url>%2F2018%2F06%2F20%2FPytorch0-4-0%E5%8D%87%E7%BA%A7%E6%A6%82%E8%BF%B0%E6%96%B0%E6%89%8B%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[pytorch0.4支持了Windows系统的开发，在首页即可使用pip安装pytorch和torchvision。 说白了，以下文字就是来自官方文档60分钟入门的简要翻译. pytorch是啥python的科学计算库，使得NumPy可用于GPU计算，并提供了一个深度学习平台使得灵活性和速度最大化 入门Tensors(张量) Tensors与NumPy的ndarrays类似，另外可以使用GPU加速计算 未初始化的5*3的矩阵:x = torch.empty(5, 3) 随机初始化的矩阵:x = torch.rand(5, 3) 全零矩阵,定义数据类型:x = torch.zeros(5, 3, dtype=torch.long) 由数据构造矩阵:x = torch.tensor([5.5, 3]) 由已存在张量构造矩阵，性质与之前张量一致: 12x = x.new_ones(5, 3, dtype=torch.double) x = torch.randn_like(x, dtype=torch.float) 获取维度:print(x.size()) Operations有多种operation的格式，这里考虑加法 12y = torch.rand(5, 3)print(x + y) 1print(torch.add(x, y)) 123result = torch.empty(5, 3)torch.add(x, y, out=result)print(result) 123# adds x to yy.add_(x)print(y) operations中需要改变张量本身的值，可以在operation后加,比如`x.copy(y), x.t_()` 索引:print(x[:, 1]) 改变维度:x.view(-1, 8) 和Numpy的联系torch tensor 和 numpy array之间可以进行相互转换，他们会共享内存位置，改变一个，另一个会跟着改变。 tensor to array1234a = torch.ones(5)b = a.numpy()a.add_(1)print(a,b) array to tensor123456import numpy as npa = np.ones(5)b = torch.from_numpy(a)np.add(a, 1, out=a)print(a)print(b) CUDA Tensorstensor可以使用.to方法将其移动到任何设备。 123456789# let us run this cell only if CUDA is available# We will use ``torch.device`` objects to move tensors in and out of GPUif torch.cuda.is_available(): device = torch.device(&quot;cuda&quot;) # a CUDA device object y = torch.ones_like(x, device=device) # directly create a tensor on GPU x = x.to(device) # or just use strings ``.to(&quot;cuda&quot;)`` z = x + y print(z) print(z.to(&quot;cpu&quot;, torch.double)) # ``.to`` can also change dtype together! Autograd(自动求导)pytorch神经网络的核心模块就是autograd，autograd模块对Tensors上的所有operations提供了自动求导。 Tensortorch.Tensor是模块中的核心类，如果设置属性.requires_grad = True,开始追踪张量上的所有节点操作，指定其是否计算梯度。使用.backward()方法进行所有梯度的自动求导，张量的梯度会累积到.grad属性中。 .detach()停止张量的追踪，从梯度计算中分离出来；另外在评估模型时一般使用代码块with torch.no_grad():,因为模型中通常训练的参数也会有.requires_grad = True,这样写可以停止全部张量的梯度更新。 Function类是autograd的变体，Tensor和Function相互交错构建成无环图，编码了完整的计算过程，每个Variable(变量)都有.grad_fn属性，引用一个已经创建了的Tensor的Function. 如上，使用.backward()计算梯度。如果张量是一个标量(只有一个元素),不需要对.backward()指定参数；如果张量不止一个元素，需要指定.backward()的参数，其匹配张量的维度。 1234567891011121314151617import torchx = torch.ones(2, 2, requires_grad=True)print(x)y = x + 2print(y)print(y.grad_fn)z = y * y * 3out = z.mean()print(z, out)a = torch.randn(2, 2)a = ((a * 3) / (a - 1))print(a.requires_grad)a.requires_grad_(True) # 改变a张量内在的属性print(a.requires_grad)b = (a * a).sum()print(b.grad_fn) Gradients反向传播时，由于out是一个标量，out.backward()等效于out.backward(torch.tensor(1)) 123456789101112131415161718192021out.backward()print(x.grad)x = torch.randn(3, requires_grad=True)y = x * 2while y.data.norm() &lt; 1000: y = y * 2print(y)gradients = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)y.backward(gradients)print(x.grad)print(x.requires_grad)print((x ** 2).requires_grad)with torch.no_grad(): print((x ** 2).requires_grad) 神经网络神经网络可以用torch.nn构建。nn依赖于autograd定义模型和求导，nn.Module定义网络层，方法forward(input)返回网络输出。 举例说明，如下是对数字图片分类的卷积网络架构。 这是一个简单的前馈神经网络，将输入数据依次通过几层网络层后最终得到输出。 神经网络典型的训练步骤如下： 定义神经网络及学习的参数(权重) 迭代输入数据 将输入数据输入到网络结构中 计算代价函数 误差向后传播 更新网络权重 weight = weight - learning_rate * gradient 定义网络123456789101112131415161718192021222324252627282930313233343536373839import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super(Net, self).__init__() # 1 input image channel, 6 output channels, 5x5 square convolution # kernel self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # an affine operation: y = Wx + b self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): # Max pooling over a (2, 2) window x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # If the size is a square you can only specify a single number x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # all dimensions except the batch dimension num_features = 1 for s in size: num_features *= s return num_featuresnet = Net()print(net) out: 1234567Net( (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1)) (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) (fc1): Linear(in_features=400, out_features=120, bias=True) (fc2): Linear(in_features=120, out_features=84, bias=True) (fc3): Linear(in_features=84, out_features=10, bias=True)) 可以仅定义forward()函数，当使用autograd时backward()被自动定义。可以在forward()函数中使用任何operation操作。 net.parameters()返回模型中的可学习参数。 123params = list(net.parameters())print(len(params))print(params[0].size()) # conv1&apos;s .weight 使所有参数的梯度归零然后开始计算梯度 12net.zero_grad()out.backward(torch.randn(1, 10)) 代价函数代价函数将(output,target)作为输入，计算output与target之间的距离。 nn模块中有几种不同的代价函数选择，最简单的是nn.MSELoss，计算均方误差 eg： 1234567output = net(input)target = torch.arange(1, 11) # a dummy target, for exampletarget = target.view(1, -1) # make it the same shape as outputcriterion = nn.MSELoss()loss = criterion(output, target)print(loss) 按照向后传播的方向传播loss，使用grad_fn可以查看整个流程的计算图 1234input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear -&gt; MSELoss -&gt; loss 使用loss.backward()，流程中所有requres_grad=True的张量累积它的梯度至.grad 123print(loss.grad_fn) # MSELossprint(loss.grad_fn.next_functions[0][0]) # Linearprint(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU 向后传播loss.backward()传播误差， 123456789net.zero_grad() # zeroes the gradient buffers of all parametersprint(&apos;conv1.bias.grad before backward&apos;)print(net.conv1.bias.grad)loss.backward()print(&apos;conv1.bias.grad after backward&apos;)print(net.conv1.bias.grad) 更新权重误差每次传播后，需要对权重进行更新，简单的更新方式如下： 123learning_rate = 0.01for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) torch.optim实现了这一过程，并有着不同的更新规则GD, Nesterov-SGD, Adam, RMSProp， 1234567891011import torch.optim as optim# create your optimizeroptimizer = optim.SGD(net.parameters(), lr=0.01)# in your training loop:optimizer.zero_grad() # zero the gradient buffersoutput = net(input)loss = criterion(output, target)loss.backward()optimizer.step() # Does the update note: 每次迭代时由于梯度的累积，需要手动将梯度归零optimizer.zero_grad()]]></content>
      <categories>
        <category>Pytorch</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Pytorch</tag>
        <tag>Pytorch0.4.0</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[唐老师研究生毕业演讲]]></title>
    <url>%2F2018%2F06%2F20%2F%E5%94%90%E8%80%81%E5%B8%88%E7%A0%94%E7%A9%B6%E7%94%9F%E6%AF%95%E4%B8%9A%E6%BC%94%E8%AE%B2%2F</url>
    <content type="text"><![CDATA[尊敬的何院士、各位嘉宾、各位老师、同学们： 大家下午好！]]></content>
      <categories>
        <category>毕业演讲</category>
      </categories>
      <tags>
        <tag>毕业演讲</tag>
        <tag>唐老师</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win10+Anaconda+tensorflow1.8+pytorch0.4.0注意事项]]></title>
    <url>%2F2018%2F06%2F12%2Fwin10-Anaconda-tensorflow1-8-pytorch0-4-0%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[注意事项 Anaconda会自带python3.6，所以为了避免环境配置乱套，删除本机独立安装的python。 不要按网上配置虚拟环境，比如TensorFlow配置一个虚拟环境，pytorch配置一个虚拟环境……keras……cafee……只要一个环境即可。 win10+Anaconda3-5.2.0+tensorflow1.8+pytorch0.4.0 在windows PowerShell中确定python环境在Anaconda中 Anaconda注意：自动添加到环境变量其它事项一路安装，普通套路。 TensorFlow1、TensorFlow或者pytorch，无论什么框架，越新越好，新的功能多bug少，这里用的TensorFlow1.8。 2、TensorFlow和pytorch最好都用conda装，但是这里conda install tensorflow只会给你比较低的版本，所以TensorFlow安装在这里使用了：1conda install --channel https://conda.anaconda.org/conda-forge tensorflow 可能会下载很慢，如果有部分下载未成功，重新执行命令即可，之前下载的会保留。 Pytorch同样遵循使用最新框架原则。我自己电脑用的pytorch-CPU版本，所以执行：12conda install conda install pytorch-cpu -c pytorchpip install torchvision 在实验室服务器用的是cuda9.0版本12pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-win_amd64.whl pip3 install torchvision 安装成功之后效果： PyCharm注意事项在不用虚拟幻境情况下，好处就是不用切换环境配置了，直接一个 Anaconda\python.exe全部搞定，如图： 附录鄙视链：caffe-pytorch-tensorflow-caffe2- caffetorch-slim-tensorflow-keras]]></content>
      <categories>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Anaconda</tag>
        <tag>tensorflow</tag>
        <tag>pytorch</tag>
        <tag>环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch0.4.0重大更新]]></title>
    <url>%2F2018%2F06%2F11%2FPyTorch0.4.0%E9%87%8D%E5%A4%A7%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[一、重大核心变化包括 Tensor/Variable 合并 零维张量 数据类型 迁移指南 二、现添加的新特征包括 Tensors： 全面支持高级索引 快速傅立叶变换 神经网络： 计算时的存储权衡 bottleneck-识别代码中热点（hotspots）的工具 torch.distributions 24 个基础的概率分布 增加cdf、方差、信息熵、困惑度等 分布式训练 易于使用的 Launcher utility NCCL2 后端 C++拓展 Windows 支持 ONNX 改进 RNN 支持 三、性能改进 四、Bug 修复 五、torchvision的一些变化1.torchvision.transform中函数torchvision.transforms.`Scale(*args, **kwargs)即将被函数torchvision.transforms.Resize`(size, interpolation=2)代替。（参考官方文档：点击打开链接） 2.torchvision.transform中函数torchvision.transforms.`RandomSizedCrop(*args, **kwargs)即将被函数torchvision.transforms.RandomResizedCrop`(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)代替。（参考官方文档：点击打开链接） 六、安装方式——Windows安装【方法一】pip直接安装。官网（点击打开链接）给出的安装步骤如下图所示（根据CUDA版本以及Python版本选择）。 Run this command: 12pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp36-cp36m-win_amd64.whl pip3 install torchvision 这里我是下载好torch-0.4.0-cp36-cp36m-win_amd64.whl文件到本地之后才安装的。进入Anaconda Prompt，然后进入文件所在目录： 打开cmd命令提示符，先利用anaconda创建一个虚拟环境，命名为pytorch4 1conda create -n pytorch4 python=3.6 激活刚才创建好的虚拟环境 1activate pytorch4 安装pytorch0.4.0 1pip install torch-0.4.0-cp35-cp35m-win_amd64.whl 注：根据自己的配置选择whl下载来链接 安装torchvision1pip install torchvision 简单测试安装是否成功123pythonimport torchprint(torch.__version__) 如果输出0.4.0，那么恭喜Windows下的PyTorch0.4.0安装成功！]]></content>
      <categories>
        <category>PyTorch</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>PyTorch</tag>
        <tag>机器学习</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mnist手写数字识别]]></title>
    <url>%2F2018%2F06%2F09%2FMnist%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%2F</url>
    <content type="text"><![CDATA[minist_mpl.py1234567891011121314151617181920212223242526272829303132333435 #encoding:utf-8import kerasfrom keras.datasets import mnistfrom keras.models import Sequentialfrom keras.layers import Dense,Activation,Dropoutfrom keras.optimizers import SGD,Adadeltafrom keras.models import save_modelimport matplotlib.pyplot as plt(x_train,y_train),(x_test,y_test) = mnist.load_data()x_train = x_train.reshape(60000,28*28).astype('float32') #转换数据格式x_test = x_test.reshape(10000,28*28).astype('float32')x_train /= 255 #训练数据归一化x_test /= 255y_train = keras.utils.to_categorical(y_train,10) #one-hot编码y_test = keras.utils.to_categorical(y_test,10)print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)modle = Sequential()#第一层隐层，64个神经元modle.add(Dense(256,activation='relu',input_dim=28*28))#第二层隐层，64个神经元modle.add(Dense(256,activation='relu'))modle.add(Dropout(0.5))#输出层，10个神经元modle.add(Dense(10,activation='softmax'))sgd = SGD(lr=0.01,decay=1e-6,momentum=0.9,nesterov=True)modle.compile(loss='categorical_crossentropy',optimizer='adagrad',metrics=['accuracy'])modle.fit(x_train,y_train,epochs=10,batch_size=128)score = modle.evaluate(x_test,y_test,batch_size=128)print(score)modle.save('MLP_minist.h5') 123456789101112131415161718192021222324252627282930313233343536373839#encoding:utf-8import kerasfrom keras.datasets import mnistfrom keras.models import Sequential,save_modelfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2Dfrom keras.optimizers import SGD,Adadelta(x_train,y_train),(x_test,y_test) = mnist.load_data() #加载数据print(x_train.shape,x_test.shape)x_train = x_train.reshape(60000,28,28,1).astype('float32') #二维数据x_test = x_test.reshape(10000,28,28,1).astype('float32')x_train /= 255 #训练数据归一化x_test /= 255y_train = keras.utils.to_categorical(y_train) #one-hot编码y_test = keras.utils.to_categorical(y_test)num_classes = y_test.shape[1]model = Sequential() #创建序列模型model.add(Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1))) #第一层卷积层model.add(MaxPooling2D(pool_size=(2,2))) #池化层model.add(Conv2D(64,(3,3),activation='relu')) #第二层卷积层model.add(MaxPooling2D(pool_size=(2,2))) #池化层model.add(Flatten()) #铺平当前节点model.add(Dense(128,activation='relu')) #全连接层model.add(Dropout(0.5)) #随机失活model.add(Dense(num_classes,activation='softmax'))model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) #编译模型model.fit(x_train,y_train,batch_size=128,epochs=10) #训练模型score = model.evaluate(x_test,y_test,batch_size=128) #评价模型print(score) #打印分类准确率model.save('CNN_minist.h5')]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Keras</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[交叉验证集、测试集]]></title>
    <url>%2F2018%2F06%2F09%2F%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E9%9B%86%E3%80%81%E6%B5%8B%E8%AF%95%E9%9B%86%2F</url>
    <content type="text"><![CDATA[什么有交叉验证：主要是因为训练集较小。无法直接像前面那样只分出训练集，验证集，测试就可以了（简单交叉验证）。 最佳的数据分类情况是把数据集分为三部分，分别为：训练集(train set)，验证集(validation set)和测试集(test set) 验证集和测试集两者的主要区别是：验证集用于进一步确定模型中的超参数(例如正则项系数、ANN{Artificial Neural Network}中隐含层的节点个数、网络层数、迭代次数、学习率)而测试集只是用于评估模型的精确度(即泛化能力)！ 举个例子：假设建立一个BP神经网络，对于隐含层的节点数目，我们并没有很好的方法去确定。一般将节点数设定为某一具体的值，通过训练集训练出相应的参数后，再由交叉验证集去检测该模型的误差；然后再改变节点数，重复上述过程，直到交叉验证误差最小。此时的节点数可以认为是最优节点数，即该节点数(这个参数)是通过交叉验证集得到的。 而测试集是在确定了所有参数之后，根据测试误差来评判这个学习模型的；也可以说是用来评估模型的泛化能力。所以，验证集主要主要是用于模型的调参。 “交叉验证法“ (cross validation)先将数据集D 划分为k 个大小相似的互斥子集， 即D = D**1 ∪ D**2 ∪**… ∪ Dk, Di ∩ Dj = ø (i≠j) . 每个子集Di 都尽可能保持数据分布的一致性，即从D 中通过分层采样得到. 然后，每次用k-1 个子集的并集作为训练集，余下的那个子集作为测试集;这样就可获得k组训练/测试集，从而可进行k 次训练和测试，最终返回的是这k 个测试结果的均值**。显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值，为强调这一点，通常把交叉验证法称为” k 折**/倍**交叉验证“ (k-fold cross validation). k 最常用的取值是10 ，此时称为10折交叉验证; 其他常用的k 值有5、20 等. 为了避免其他属性携带的信息被训练集中未出现的属性值”抹去”，在估计概率值时通常要进行”平滑” (smoothing) ，常用”拉普拉斯修正“，所以，P(c)和P(xi|c)修正为： 其中N 表示训练集D 中可能的类别数，Ni表示第 与留出法相似，将数据集D 划分为k 个子集同样存在多种划分方式.为减小因样本划分不同而引入的差别，k折交叉验证通常要随机使用不同的划分重复p 次。最终的评估结果是这p 次k 折交叉验证结果的均值，例如常见的有”10 次10 折交叉验证。 假定数据集D中包含m个样本，若令k=m ，则得到了交叉验证法的一个特例:留一法(Leave- One-Out比，简称LOO) . 显然，留一法不受随机样本划分方式的影响，因为m个样本只有唯一的方式划分为m个子集**—**每个子集包含一个样本;留一法使用的训练集与初始数据集相比只少了一个样本，这就使得在绝大多数情况下，留一法中被实际评估的模型与期望评估的用D 训练出的模型很相似.因此，留一法的评估结果往往被认为比较准确.然而，留一法也有其缺陷:在数据集比较大时，训练m个模型的计算开销可能是难以忍受的(例如数据集包含1 百万个样本，则需训练1 百万个模型)，而这还是在未考虑算法调参的情况下.另外，留一法的估计结果也未必永远比其他评估方法准确;”没有免费的午餐”定理对实验评估方法同样适用.]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>模型评估</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[偏差、方差、噪声]]></title>
    <url>%2F2018%2F06%2F09%2F%E5%81%8F%E5%B7%AE%E3%80%81%E6%96%B9%E5%B7%AE%E3%80%81%E5%99%AA%E5%A3%B0%2F</url>
    <content type="text"><![CDATA[代价敏感错误率：为不同错误类型赋予不同的权重。不同类型的错误所造成的后果不同.例如在医疗诊断中，错误地把患者诊断为健康人与错误地把健康人诊断为患者，看起来都是犯了”一次错误”但后者的影响是增加了进一步检查的麻烦，前者的后果却可能是丧失了拯救生命的最佳时机;再如，门禁系统错误地把可通行人员拦在门外，将使得用户体验不佳，但错误地把陌生人放进门内，则会造成严重的安全事故.为权衡不同类型错误所造成的不同损失，可为错误赋予”非均等代价” 。 在非均等代价下， ROC 曲线不能直接反映出学习器的期望总体代价，而”代价曲线“ 则可达到该目的.代价曲线图的横轴是取值为[0，1]的正例概率代价;纵轴是取值为[0，1] 的归一化代价。 偏差（Bias）和方差（Variance）偏差（Bias）：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据。 方差（Variance）：描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散。 偏差：形容数据跟我们期望的中心差得有多远，算是“有监督的”，有人的知识参与指标； 方差：形容数据分散程度的，算是“无监督的”，客观的指标。 噪声：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度. 偏差一方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的. 给定学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小. 一般来说偏差与方差是有冲突的，这称为偏差—方差窘境，给定学习任务，假定我们能控制学习算法的训练程度（例如决策树可控制层数，神经网络可控制训练轮数，集成学习方法可控制基学习器个数），则在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以便学习器产生显著变化，此时偏差主导了泛化错误率;随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率;在训练程度充足后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合. 为什么KNN（k最近邻k-Nearest Neighbor）算法在增大k时，偏差会变大；但RF（Random Forest随机森林）增大树的数目时偏差却保持不变；GBDT（Gradient Boosting）在增大树的数目时偏差却又能变小。 对于KNN算法，k值越大，表示模型的学习能力越弱，因为k越大，它越倾向于从“面”上考虑做出判断，而不是具体地考虑一个样本近身的情况来做出判断，所以，它的偏差会越来越大。 对于RF，我们实际上是部分实现了多次训练取均值的效果，每次训练得到的树都是一个很强的学习者，每一个的方差都比较大，但综合起来就会比较小。好比一个很强的学习者学习时，刮着西风，它会据此调整自己的瞄准方法，另一个很强的学习者学习时刮着东风，（西风、东风可以理解为不同训练集中的噪声）它也会据此调整自己的瞄准方法，在测试样本时，一个误差向西，一个误差向东，刚好起到互相抵消的作用，所以方差会比较小。但是由于每棵树的偏差都差不多，所以，我们取平均时，偏差不会怎么变化。 为什么说是部分实现了多次训练取均值的效果而不是全部呢？因为我们在训练各棵树时，是通过抽样样本集来实现多次训练的，不同的训练集中不可避免地会有重合的情况，此时，就不能认为是独立的多次训练了，各个训练得到的树之间的方差会产生一定的相关性，训练集中重合的样本越多，则两棵树之间的方差的相关性越强，就越难达成方差互相抵消的效果。 对于GBDT，N棵树之间根本就不是一种多次训练取均值的关系，而是N棵树组成了相关关联，层层递进的超级学习者，可想而知，它的方差一定是比较大的。但由于它的学习能力比较强，所以，它的偏差是很小的，而且树的棵树越多，学习能力就越强，偏差就越小。也就是说，只要学习次数够多，预测的均值会无限接近于目标。简单讲就是GBDT的N棵树实际上是一个有机关联的模型，不能认为是N个模型。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>笔记</tag>
        <tag>性能评估</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP-单词拆分 I]]></title>
    <url>%2F2018%2F06%2F09%2FDP-%E5%8D%95%E8%AF%8D%E6%8B%86%E5%88%86%20I%2F</url>
    <content type="text"><![CDATA[题目描述给定一个非空字符串 s 和一个包含非空单词列表的字典 wordDict，判定 s 是否可以被空格拆分为一个或多个在字典中出现的单词。说明：拆分时可以重复使用字典中的单词。你可以假设字典中没有重复的单词。示例 1：输入: s = “leetcode”, wordDict = [“leet”, “code”]输出: true解释: 返回 true 因为 “leetcode” 可以被拆分成 “leet code”。 示例 2：输入: s = “applepenapple”, wordDict = [“apple”, “pen”]输出: true解释: 返回 true 因为 “applepenapple” 可以被拆分成 “apple pen apple”。注意你可以重复使用字典中的单词。 示例 3：输入: s = “catsandog”, wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]输出: false 算法思路动态规划的思路：将问题拆分成更小的子问题。用dp[i]表示0到i的子字符串是否可以拆分成满足条件的单词，在计算dp[i]的时候，我们已经知道dp[0],dp[1],…,dp[i-1],如果以i为结尾的j~i子串是满足条件的，并且0~j的子串也是在字典中的，那么dp[i]就是true。用公式表示就是： dp[j]&amp;&amp;s.substring[j,i+1]∈dict DP实现123456789101112131415class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123;; boolean [] dp = new boolean[s.length()+1]； dp[0] = true; for(int i = 0; i &lt; s.length(); i++)&#123; for(int j = 0; j &lt;= i; j++)&#123; if(dp[j] &amp;&amp; wordDict.contains(s.substring(j, i+1)))&#123; dp[i+1] = true; break; &#125; &#125; &#125; return dp[s.length()]; &#125;&#125; DFS解法，超时1234567891011121314151617181920212223242526class Solution &#123; boolean dfs(String s, List&lt;String&gt; wordDict, int index)&#123; // 超时 String left = s.substring(index, s.length()); if(wordDict.contains(left))&#123; return true; &#125; List&lt;Integer&gt; list = new ArrayList(); for(int i = index; i &lt; s.length(); i++)&#123; String temp = s.substring(index, i+1); if(wordDict.contains(temp))&#123; list.add(i+1); &#125; &#125; for(Integer each:list) &#123; if(dfs(s, wordDict, each))&#123; return true; &#125; &#125; return false; &#125; boolean flag = false; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; return dfs(s, wordDict, 0); &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
        <tag>算法</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫]]></title>
    <url>%2F2018%2F06%2F09%2FPython%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[文本爬取12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#encoding:utf-8import requests,urllib3.request,time,osimport random,csv,socket,http.clientfrom bs4 import BeautifulSoupdef get_contend(url, data = None): #获取网页中html代码 header=&#123;'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'Accept-Encoding': 'zh-CN,zh;q=0.9', 'Accept-Language': 'zh-CN,zh;q=0.8', 'Connection': 'keep-alive', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36' &#125; timeout = random.choice(range(80,180)) while True: try: rep = requests.get(url,headers = header,timeout=timeout) rep.encoding = 'utf-8' break except socket.timeout as e: print ('3',e) time.sleep(random.choice.range(8,15)) except socket.error as e: print ('4',e) time.sleep(random.choice.range(20,60)) except http.client.BadStatusLine as e: print ('5',e) time.sleep(random.choice.range(30,80)) except http.client.IncompleteRead as e: print ('6',e) time.sleep(random.choice.range(5,15)) return rep.textdef get_data(html_text): final = [] bs = BeautifulSoup(html_text,'html.parser') #创建BeautifulSoup对象 body = bs.body #获取body部分 data = body.find('div',&#123;'id':'7d'&#125;) #找到需要爬取部分的div ul = data.find('ul') #获取ul部分 li = ul.find_all('li') #获取所有的li for day in li: #对li标签中内容进行遍历 temp = [] date =day.find('h1').string #找到日期 temp.append(date) #将日期添加到temp中 p = day.find_all('p') #找到每个li中的所有p标签 temp.append(p[0].string,) #第一个p标签中的天气状况添加到temp if p[1].find('span') == None: t_highest = None else: t_highest = p[1].find('span').string #找到最高温 t_highest = t_highest.replace('C','') t_lowest = p[1].find('i').string # 找到最低温 t_lowest = t_lowest.replace('C','') temp.append(t_highest) temp.append(t_lowest) final.append(temp) return finaldef write_data(data,name): #将数据写入文件 file_name = name with open(file_name, 'a', errors='ignore', newline='') as f: f_csv = csv.writer(f) f_csv.writerows(data)if __name__ == '__main__': url = 'http://www.weather.com.cn/weather/101190401.shtml' html = get_contend(url) result = get_data(html) print(result) write_data(result,'weather.csv') 图虫图片爬取按标签爬取12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273__author__ = 'Result_Lv'#encoding:utf-8import osimport jsonimport timeimport requestsimport numpy as npfrom urllib import request,errordef get_json(url): header = &#123;'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, br', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36' &#125; rep = requests.get(url, headers = header) #请求json地址 json_dict = json.loads(rep.text) #解析json return json_dict #返回json字典def get_album_name(json_dict): album_name = [] postlist = json_dict['postList'] for i in range(len(postlist)): if postlist[i]['title'] == '': #图集标题为空时，命名为默认 album_name.append('Default' + str(i)) else: album_name.append(postlist[i]['title']) return album_namedef get_photo_id(json_dict): #获得所有照片的ID author_id = [] album_id = [] post_list = json_dict['postList'] for i in range(len(post_list)): #获取每个图集的照片ID photo_id = [] author_id.append(post_list[i]['author_id']) # 获取每个图集作者ID for j in range(len(post_list[i]['images'])): photo_id.append(post_list[i]['images'][j]['img_id']) #将所有每个图集里的照片全部添加到list album_id.append(photo_id) return author_id,album_iddef download_album(path,album_name,author_id,album_id): #下载图集 for i in range(len(album_id)): if not os.path.exists(path + album_name[i]): #若不存在对应图集的文件夹 try: os.makedirs(path + album_name[i]) #以图集名创建文件夹 except OSError as e: print(e) continue print('正在下载第' + str(i + 1) + '个图册:' + album_name[i]) for j in range(len(album_id[i])): fileurl = 'https://photo.tuchong.com/' + str(author_id[i]) +'/f/' + str(album_id[i][j]) + '.jpg' #生成每张照片Url filename = path + album_name[i] + '/' + str(j+1) + '.jpg' #命名照片 print(' 正在下载第' + str(j+1) + '张照片:' + fileurl) with open(filename,'w'): try: request.urlretrieve(fileurl,filename) #下载照片 time.sleep(np.random.rand()) #下载间隔 except error.HTTPError as e: print(e)if __name__ == '__main__': page = 3 #爬取页数 path = 'F:/少女/' #存放路径 for i in range(page): url = 'https://tuchong.com/rest/tags/少女/posts?page=' + str(i+1) + '&amp;count=20&amp;order=weekly' #tag的json地址 json_dict = get_json(url) album_name = get_album_name(json_dict) para = get_photo_id(json_dict) author_id = para[0] album_id = para[1] download_album(path,album_name,author_id,album_id) 按作者爬取12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#encoding:utf-8import osimport jsonimport timeimport requestsimport numpy as npfrom urllib import request,errordef get_json(url): #解析json header = &#123;'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, br', 'Accept-Language': 'zh-CN,zh;q=0.9', 'Connection': 'keep-alive', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36' &#125; rep = requests.get(url, headers = header) #请求json地址 json_dict = json.loads(rep.text) #解析json return json_dict #返回json字典def get_all_photo_id(json_dict): #获得所有照片的ID #post_id = [] photo_id = [] post_list = json_dict['post_list'] author_id = post_list[0]['author_id'] #获取作者ID author_name = post_list[0]['site']['name'] #获取作者姓名 # for i in range(len(post_list)): #获取所有图集ID # post_id.append(post_list[i]['post_id']) for i in range(len(post_list)): #获取每个图集的照片ID for j in range(len(post_list[i]['images'])): photo_id.append(post_list[i]['images'][j]['img_id']) #将所有每个图集里的照片全部添加到list return author_name,author_id,photo_iddef download_photo(path,author_id,photo_id): #下载全部照片 if not os.path.exists(path): os.makedirs(path) for i in range(len(photo_id)): filename = path + '/' + str(i+1) + '.jpg' fileurl = 'https://photo.tuchong.com/' + str(author_id) + '/f/' + str(photo_id[i]) + '.jpg' print(' 第' + str(i + 1) + '张图片:' + fileurl) with open(filename,'w'): try: request.urlretrieve(fileurl,filename) #下载照片 time.sleep(np.random.rand()) #下载间隔 except error.HTTPError as e: print(e)if __name__ == '__main__': page = 3 for i in range(page): url = 'https://thomaskksj.tuchong.com/rest/2/sites/395013/posts?count=20&amp;page=' + str(i + 1) #作者主页的json地址 print('正在下载第' + str(i+1) + '页:' + url) json_dict = get_json(url) para = get_all_photo_id(json_dict) author_name = para[0] author_id = para[1] photo_id = para[2] path = 'F:/' + author_name + '/page' + str(i + 1) download_photo(path,author_id,photo_id)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最长公共子串-最长公共子序列]]></title>
    <url>%2F2018%2F06%2F09%2F%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E4%B8%B2-%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[最长公共子串DP实现1234567891011121314151617181920212223242526272829public static int maxSubStr(String str1, String str2) &#123; int result = 0; int index = 0; int len1 = str1.length(); int len2 = str2.length(); int [][] dp = new int [len1][len2]; for(int i = 0; i &lt; len1; ++i) &#123; for(int j = 0; j &lt; len2; ++j) &#123; if(str1.charAt(i) == str2.charAt(j)) &#123; if(i &gt; 0 &amp;&amp; j &gt; 0) &#123; dp[i][j] = dp[i-1][j-1] + 1; // 状态转移 if(dp[i][j] &gt; result) &#123; result = dp[i][j]; index = i; // 记录最大子串的最后一个下标 &#125; // result = result &gt; dp[i][j] ? result : dp[i][j]; &#125;else &#123; dp[i][j] = 1; result = result &gt; dp[i][j] ? result : dp[i][j]; &#125; &#125; &#125; &#125; System.out.println(result); for(int i = index - result + 1; i &lt;= index; i++) &#123; System.out.print(str1.charAt(i) + " "); &#125; return result;&#125; 最长公共子序列####动态规划假设Z=&lt;z1,z2,⋯,zk&gt;是X与Y的LCS， 我们观察到如果Xm=Yn，则Zk=Xm=Yn，有Zk−1是Xm−1与Yn−1的LCS；如果Xm≠Yn，则Zk是Xm与Yn−1的LCS，或者是Xm−1与Yn的LCS。因此，求解LCS的问题则变成递归求解的两个子问题。但是，上述的递归求解的办法中，重复的子问题多，效率低下。改进的办法——用空间换时间，用数组保存中间状态，方便后面的计算。这就是动态规划（DP)的核心思想了。DP求解LCS用二维数组c[i][j]记录串x1x2⋯xi与y1y2⋯yj的LCS长度，则可得到状态转移方程 DP实现1234567891011121314151617181920public static int maxSubSequence(String str1, String str2) &#123; int len1 = str1.length(); int len2 = str2.length(); int [][] dp = new int[len1][len2]; for(int i = 0; i &lt; len1; ++i) &#123; for(int j = 0; j &lt; len2; ++j) &#123; if(i &gt; 0 &amp;&amp; j &gt; 0) &#123; if(str1.charAt(i) == str2.charAt(j)) &#123; dp[i][j] = dp[i-1][j-1] + 1; &#125;else &#123; dp[i][j] = dp[i-1][j] &gt; dp[i][j-1] ? dp[i-1][j] : dp[i][j-1]; &#125; &#125;else if(str1.charAt(i) == str2.charAt(j)) &#123; dp[i][j] = 1; &#125; &#125; &#125; System.out.println(dp[len1 - 1][len2 - 1]); return dp[len1-1][len2-1];&#125;]]></content>
      <categories>
        <category>面试题</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>回溯</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查准率precision和查全率recall、F1]]></title>
    <url>%2F2018%2F06%2F09%2F%E6%9F%A5%E5%87%86%E7%8E%87precision%E5%92%8C%E6%9F%A5%E5%85%A8%E7%8E%87recall%E3%80%81F1%2F</url>
    <content type="text"><![CDATA[真正例（true positive）、假正例（false positive）、真反例（true negative）、假反例（false negative），分别用TP、FP、TN、FN表示相应样例数，样例总数=TP+FP+TN+FN；分类结果混淆矩阵： 真实情况 预测结果 正例 反例 正例 TP（真正例） FN（假反例） 反例 FP（假正例） TN（真反例） 查准率（precision）：被认定为正例的里面，判断正确的比例。 查全率（recall）：真实正例里，被判断出为正例的比例。 查准率和查全率是一对矛盾的度量.一般来说，查准率高时，查全率往往偏低;而查全率高时，查准率往往偏低,可以通过P-R曲线来取两者的平衡值 若一个学习器P-R曲线被另一个学习器的曲线完全”包住“,则可断言后者的性能优于前者， 例如图中学习器A 的性能优于学习器C; 如果两个学习器的P-R 曲线发生了交叉7,例如图中的A 与B ，则难以一般性地断言两者孰优孰劣，只能在具体的查准率或查全率条件下进行比较然而，在很多情形下，人们往往仍希望把学习器A 与B 比出个高低. 这时一个比较合理的判据是比较P-R 曲线节面积的大小。 “平衡点“是”查准率=查全率“时的取值。 但更常用的使用F1来衡量查准率与查全率； F1基于查准率与查全率的调和平均： ，sum为样例总数， 具体应用中可能对P和R有不同的倚重。比如商品推荐中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，这时候查准率更重要。而在逃犯检索系统中，更希望尽可能少漏掉逃犯，此时查全率更重要。 F1度量的一般形式F**β（加权调和平均**）就可以表达这种偏好。 即 ß = 1时退化为标准的F1,当β&gt;1意味着P占比重更大，反之则是R。 ROC、AUCROC:全称“受试者工作特征”，表达了模型的泛化能力。其纵坐标为“TPR真正例率”；横坐标为“FPR假正例率”。 ROC曲线根据模型的排序结果，一个个划分正负，每次得出两个值TPR,FPR。很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值进行比较，若大于阈值则分为正类，否则为反类。为啥在ROC曲线画一个y=x呢，那表示随机猜测的ROC。 AUC:ROC曲线下的面积.AUC=1,是完美分类器(并不存在)；0.5。AUC 越大，意味着辨别能力越强。 与P-R图相似，如果一条ROC曲线包含另一条ROC曲线，则前者的学习器性能更优越。如果曲线有交叉，则可以通过计算AUC大小得到。 代价敏感错误率、代价曲线代价敏感错误率：为不同错误类型赋予不同的权重。不同类型的错误所造成的后果不同.例如在医疗诊断中，错误地把患者诊断为健康人与错误地把健康人诊断为患者，看起来都是犯了”一次错误”但后者的影响是增加了进一步检查的麻烦，前者的后果却可能是丧失了拯救生命的最佳时机;再如，门禁系统错误地把可通行人员拦在门外，将使得用户体验不佳，但错误地把陌生人放进门内，则会造成严重的安全事故.为权衡不同类型错误所造成的不同损失，可为错误赋予”非均等代价” 。 在非均等代价下， ROC 曲线不能直接反映出学习器的期望总体代价，而”代价曲线“ 则可达到该目的.代价曲线图的横轴是取值为[0，1]的正例概率代价;纵轴是取值为[0，1] 的归一化代价。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>笔记</tag>
        <tag>性能评估</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DP+回溯-单词拆分 II]]></title>
    <url>%2F2018%2F06%2F09%2FDP%2B%E5%9B%9E%E6%BA%AF-%E5%8D%95%E8%AF%8D%E6%8B%86%E5%88%86%20II%2F</url>
    <content type="text"><![CDATA[题目描述给定一个非空字符串 s 和一个包含非空单词列表的字典 wordDict，在字符串中增加空格来构建一个句子，使得句子中所有的单词都在词典中。返回所有这些可能的句子。说明：分隔时可以重复使用字典中的单词。你可以假设字典中没有重复的单词。示例 1：输入:s = “catsanddog”wordDict = [“cat”, “cats”, “and”, “sand”, “dog”]输出:[“cats and dog”,“cat sand dog”] 示例 2：输入:s = “pineapplepenapple”wordDict = [“apple”, “pen”, “applepen”, “pine”, “pineapple”]输出:[“pine apple pen apple”,“pineapple pen apple”,“pine applepen apple”]解释: 注意你可以重复使用字典中的单词。 示例 3：输入:s = “catsandog”wordDict = [“cats”, “dog”, “sand”, “and”, “cat”]输出:[] 算法思路这道题类似 Word Break I 判断是否能把字符串拆分为字典里的单词 @LeetCode 只不过要求计算的并不仅仅是是否能拆分，而是要求出所有的拆分方案。因此用递归。但是直接递归做会超时，原因是LeetCode里有几个很长但是无法拆分的情况，所以就先跑一遍Word Break I，先判断能否拆分，然后再进行拆分。 DP实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 class Solution &#123; boolean isBreak(String s, List&lt;String&gt; wordDict) &#123; boolean[] canBreak = new boolean[s.length()+1]; canBreak[0] = true; for(int i=1; i&lt;=s.length(); i++) &#123; boolean flag = false; for(int j=0; j&lt;i; j++) &#123; if(canBreak[j] &amp;&amp; wordDict.contains(s.substring(j,i))) &#123; flag = true; break; &#125; &#125; canBreak[i] = flag; &#125; return canBreak[s.length()]; &#125; void dfs(String s, List&lt;String&gt; wordDict, String str, int index)&#123; String result = str; //记录字符串状态 int len = s.length(); String tmp = s.substring(index, len); if(wordDict.contains(tmp))&#123; //最后一段存在于字典中，则保存结果 str += tmp; res.add(str); &#125; List&lt;Integer&gt; listIndex = new ArrayList(); List&lt;String&gt; listStr = new ArrayList(); for(int i = index; i &lt; len; i++)&#123; String temp = s.substring(index, i+1); if(wordDict.contains(temp))&#123; listIndex.add(i+1); listStr.add(temp); &#125; &#125; String temp = result; //保存递归前的字符串状态，以便回溯 for(int i = 0; i &lt; listIndex.size(); i++)&#123; result += listStr.get(i) + " "; dfs(s, wordDict, result, listIndex.get(i)); result = temp; &#125; &#125; List&lt;String&gt; res = new ArrayList(); public List&lt;String&gt; wordBreak(String s, List&lt;String&gt; wordDict) &#123; if(!isBreak(s, wordDict)) return res; String str = ""; dfs(s, wordDict, str, 0); return res; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>动态规划</tag>
        <tag>算法</tag>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分糖果]]></title>
    <url>%2F2018%2F06%2F09%2F%E5%88%86%E7%B3%96%E6%9E%9C%2F</url>
    <content type="text"><![CDATA[题目描述o 分糖果：科大讯飞第二道编程题 o 小明和小红是好朋友，但最近遇到一个棘手的问题，有一盒糖果要分成两份但是每颗糖果质量都不尽相同， o 但为了分配的公平每份糖的糖果数量相差不得超过1，在此条件下两份糖果的质量差距尽可能小。 o 输入一行数，包含一个数n，代表糖果数量，后面一次是n个整数一次表示每个糖果的质量，每个糖果的质量都是1到450 o 之间的一个整数，每盒最多有20个糖果。 o 输出：每个样例输出两个数字分别为两堆糖果的质量，如不相同，先小后大。 o 样例：输入：5 9 6 5 8 7 o 输出：17 18 算法思想o 回溯，在数量差值为1的结果中找出最小的质量差 Python实现1234567891011121314151617def divide(candies, num, select, sum, total, index): global min global res if(abs(total-sum*2) &lt; min): res = sum min = abs(total-sum*2) result.append(select) for i in range(len(candies)): if(index == num-1): return3 select.append(candies[index]) sum += candies[index] temp = select.copy() if(len(select) &lt;= int(num/2)+1): index += 1 divide(candies, num, temp, sum, total, index) sum -= select[len(select) - 1] select.remove(select[len(select)-1])]]></content>
      <categories>
        <category>面试题</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>Python</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+GitHub搭建个人博客]]></title>
    <url>%2F2018%2F06%2F09%2FHexo%2BGitHub%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[Hexo+GitHub搭建个人博客目录： 前言： ​ 准备工作 搭建github博客 ​ 创建仓库 ​ 绑定域名 配置SSH key ​ 测试是否成功 使用hexo写博客 ​ hexo简介 ​ 原理 注意事项 安装 初始化 ​ 修改主题 ​ 上传到github 保留CNAME、README.md等文件 常用hexo命令 ​ _config.yml 写博客 最终效果 https://dadavision.cn/ 技巧 1.前言使用github pages服务搭建博客的好处有： 全是静态文件，访问速度快； 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台； 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的； 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行； 博客内容可以轻松打包、转移、发布到其它平台； 等等； 1.1. 准备工作在开始一切之前，你必须已经： 有一个github账号，没有的话去注册一个； 安装了node.js、npm，并了解相关基础知识； 安装了git for windows（或者其它git客户端） 本文所使用的环境： Windows10企业版 node.js@8.11.2 git@2.17.1 hexo@3.7.1 2.搭建github博客2.1. 创建仓库新建一个名为你的用户名.github.io的仓库，比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 http://test.github.io 了，是不是很方便？ 由此可见，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。 几个注意的地方： 注册的邮箱一定要验证，否则不会成功； 仓库名字必须是：username.github.io，其中username是你的用户名； 仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久，我的等了半个小时才生效； 创建成功后，默认会在你这个仓库里生成一些示例页面，以后你的网站所有代码都是放在这个仓库里啦。 2.2. 绑定域名当然，你不绑定域名肯定也是可以的，就用默认的 xxx.github.io 来访问，如果你想更个性一点，想拥有一个属于自己的域名，那也是OK的。 首先你要注册一个域名，域名注册以前总是推荐去godaddy，现在觉得其实国内的阿里云、腾讯云也挺不错的，价格也不贵，毕竟是大公司，放心！或者说万网，本质上都是在万网上。 绑定域名分2种情况：带www和不带www的。 域名配置最常见有2种方式，CNAME和A记录，CNAME填写域名，A记录填写IP，由于不带www方式只能采用A记录，所以必须先ping一下你的用户名.github.io的IP，然后到你的域名DNS设置页，将A记录指向你ping出来的IP，将CNAME指向你的用户名.github.io，这样可以保证无论是否添加www都可以访问，如下： 然后到你的github项目根目录新建一个名为CNAME的文件（无后缀），里面填写你的域名，加不加www看你自己喜好，因为经测试： 如果你填写的是没有www的，比如 mygit.me，那么无论是访问 http://www.mygit.me 还是 http://mygit.me ，都会自动跳转到 http://mygit.me 如果你填写的是带www的，比如 www.mygit.me ，那么无论是访问 http://www.mygit.me 还是 http://mygit.me ，都会自动跳转到 http://www.mygit.me 如果你填写的是其它子域名，比如 abc.mygit.me，那么访问 http://abc.mygit.me 没问题，但是访问 http://mygit.me ，不会自动跳转到 http://abc.mygit.me 另外说一句，在你绑定了新域名之后，原来的你的用户名.github.io并没有失效，而是会自动跳转到你的新域名。 3.配置SSH key为什么要配置这个呢？因为你提交代码肯定要拥有你的github权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用ssh key来解决本地和服务器的连接问题。 1$ cd ~/. ssh #检查本机已存在的ssh密钥 如果提示：No such file or directory 说明你是第一次使用git。 1ssh-keygen -t rsa -C &quot;邮件地址&quot; 然后连续3次回车，最终会生成一个文件在用户目录下，打开用户目录，找到.ssh\id_rsa.pub文件，记事本打开并复制里面的内容，打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key： 将刚复制的内容粘贴到key那里，title随便填，保存。 3.1. 测试是否成功1$ ssh -T git@github.com # 注意邮箱地址不用改 如果提示Are you sure you want to continue connecting (yes/no)?，输入yes，然后会看到： Hi liuxianan! You’ve successfully authenticated, but GitHub does not provide shell access. 看到这个信息说明SSH已配置成功！ 此时你还需要配置： 12$ git config --global user.name &quot;dadavision&quot;// 你的github用户名，非昵称$ git config --global user.email &quot;dadavision@qq.com&quot;// 填写你的github注册邮箱 具体这个配置是干嘛的我没仔细深究。 4.使用hexo写博客4.1. hexo简介Hexo是一个简单、快速、强大的基于 Github Pages 的博客发布工具，支持Markdown格式，有众多优秀插件和主题。 官网： http://hexo.iogithub: https://github.com/hexojs/hexo 4.2. 原理由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。 4.3. 注意事项安装之前先来说几个注意事项： 很多命令既可以用Windows的cmd来完成，也可以使用git bash来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用git bash来执行； hexo不同版本差别比较大，网上很多文章的配置信息都是基于2.x的，所以注意不要被误导； hexo有2种_config.yml文件，一个是根目录下的全局的_config.yml，一个是各个theme下的； 4.4. 安装1$ npm install -g hexo 4.5. 初始化在电脑的某个地方新建一个名为hexo的文件夹（名字可以随便取），比如我的是F:\Workspaces\hexo，由于这个文件夹将来就作为你存放代码的地方，所以最好不要随便放。 12$ cd /f/GitBlog/hexo/$ hexo init hexo会自动下载一些文件到这个目录，包括node_modules，目录结构如下图： 这里有个’更新博客’，这里涉及一个技巧，后面讲。 12$ hexo g # 生成$ hexo s # 启动服务 执行以上命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的： hexo s是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容，很多人会碰到浏览器一直在转圈但是就是加载不出来的问题，一般情况下是因为端口占用的缘故，因为4000这个端口太常见了，可以用hexo clean。 第一次初始化的时候hexo已经帮我们写了一篇名为 Hello World 的文章，默认的主题比较丑。 4.6. 修改主题既然默认主题很丑，那我们别的不做，首先来替换一个好看点的主题。这是 官方主题。 个人比较喜欢的2个主题：hexo-theme-jekyll 和 hexo-theme-yilia。 首先下载这个主题： 12$ cd /f/Workspaces/hexo/$ git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia 下载后的主题都在这里： 另外一种更方便的方式是： 我用的next主题。 直接从官网github上，clone down下来，解压后直接放进文件夹更快。 修改_config.yml中的theme: landscape改为theme: next，然后重新执行hexo g来重新生成。 如果出现一些莫名其妙的问题，可以先执行hexo clean来清理一下public的内容，然后再来重新生成和发布。 4.7. 上传之前在上传代码到github之前，一定要记得先把你以前所有代码下载下来（虽然github有版本管理，但备份一下总是好的），因为从hexo提交代码时会把你以前的所有代码都删掉。 4.8. 上传到github如果你一切都配置好了，发布上传很容易，一句hexo d就搞定，当然关键还是你要把所有东西配置好。 首先，ssh key肯定要配置好。 其次，配置_config.yml中有关deploy的部分： 正确写法： 123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:DaDaVision/DaDaVision.github.io.git branch: master 错误写法： 1234deploy: type: github repository: https://github.com:DaDaVision/DaDaVision.github.io.git branch: master 后面一种写法是hexo2.x的写法，现在已经不行了，无论是哪种写法，此时直接执行hexo d的话一般会报如下错误： 1Deployer not found: github 或者 Deployer not found: git 原因是还需要安装一个插件： 1npm install hexo-deployer-git --save 其它命令不确定，部署这个命令一定要用git bash，否则会提示Permission denied (publickey). 打开你的git bash，输入hexo d就会将本次有改动的代码全部提交，没有改动的不会. 4.9. 保留CNAME、README.md等文件提交之后网页上一看，发现以前其它代码都没了，此时不要慌，一些非md文件可以把他们放到source文件夹下，这里的所有文件都会原样复制（除了md文件）到public目录的： 由于hexo默认会把所有md文件都转换成html，包括README.md，所有需要每次生成之后、上传之前，手动将README.md复制到public目录，并删除README.html。 这里需要注意： 在添加绑定域名后需要注意以下问题（未绑定可以不用） 需要将github上CNAME里面内容在文件工程中GitBlog\source\CNAME 这里注意新建的CNAME不要有后缀名。 4.10. 常用hexo命令常见命令 1234567hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）hexo deploy #部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本 缩写： 1234hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy 组合命令： 12hexo s -g #生成并本地预览hexo d -g #生成并上传 4.11. _config.yml这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。 需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。 4.12. 写博客定位到我们的hexo根目录，执行命令： 1hexo new &apos;哈喽&apos; hexo会帮我们在_posts下生成相关md文件，我们只需要打开这个文件就可以开始写博客了，默认生成如下内容： 当然你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。 一般完整格式如下： 123456789---title: postName #文章页面上的显示名称，一般是中文date: 2018-7-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改categories: 默认分类 #分类tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面---以下是正文 那么hexo new page &#39;postName&#39;命令和hexo new &#39;postName&#39;有什么区别呢？ 1hexo new page &quot;my-second-blog&quot; 生成如下： 最终部署时生成：GitBlog\public\my-second-blog\index.html，但是它不会作为文章出现在博文目录。 4.12.1. 写博客工具那么用什么工具写博客呢？ 推荐用Typora和Hbuilder X。 4.12.2. 如何让博文列表不显示全部内容默认情况下，生成的博文目录会显示全部的文章内容，如何设置文章摘要的长度呢？ 答案是在合适的位置加上&lt;!--more--&gt;即可。 5.最终效果可以访问我的git博客来查看效果：https://dadavision.cn 6.技巧其中生成，上传github有很多命令，以下方法可以减少繁琐，就是创建.bat批处理文件： 123f:cd GitBloghexo clean &amp; hexo g &amp;&amp; gulp &amp; hexo d &amp; hexo s 还可以设置全局快捷键：]]></content>
      <categories>
        <category>个人博客</category>
      </categories>
      <tags>
        <tag>个人博客</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>next</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回溯法思想]]></title>
    <url>%2F2018%2F06%2F09%2F%E5%9B%9E%E6%BA%AF%E6%B3%95%E6%80%9D%E6%83%B3%2F</url>
    <content type="text"><![CDATA[子集树与排列树当所给问题是从n个元素的集合S中找出满足某种性质的子集时，解空间为子集树。例如：0-1背包问题 (选或不选问题)当所给问题是从n个元素的集合S中找出满足某种性质的排列时，解空间为排列树。例如：旅行售货员问题（选择顺序问题） 算法结构 深度优先搜索与广度优先搜索算法有何区别深度优先搜索法不全部保留结点，扩展完的结点从数据存储结构栈中弹出删去，在栈中存储的结点数就是解空间树的深度，因此它占用空间较少。所以，当搜索树的结点较多，用其它方法易产生内存溢出时，深度优先搜索不失为一种有效的求解方法。广度优先搜索算法，一般需存储产生所有结点，占用的存储空间要比深度优先搜索大得多，因此，程序设计中，必须考虑溢出和节省内存空间的问题。但广度优先搜索法一般无回溯操作（即入栈和出栈的操作），所以运行速度比深度优先搜索要快些。 回溯与分支限界区别回溯法以深度优先的方式搜索解空间树T，而分支限界法则以广度优先或以最小耗费优先的方式搜索解空间树T。它们在问题的解空间树T上搜索的方法不同，适合解决的问题也就不同。一般情况下，回溯法的求解目标是找出T中满足约束条件的所有解的方案，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到极大或极小的解，即在某种意义下的最优解。相对而言，分支限界算法的解空间比回溯法大得多，因此当内存容量有限时，回溯法成功的可能性更大。 最优化处理问题在处理最优问题时，采用穷举法、回溯法或分支限界法都可以通过利用当前最优解和上界函数加速。仅就对限界剪支的效率而言，优先队列的分支限界法显然要更充分一些。在穷举法中通过上界函数与当前情况下函数值的比较可以直接略过不合要求的情况而省去了更进一步的枚举和判断；回溯法则因为层次的划分，可以在上界函数值小于当前最优解时，剪去以该结点为根的子树，也就是节省了搜索范围；分支限界法在这方面除了可以做到回溯法能做到的之外，同时若采用优先队列的分支限界法，用上界函数作为活结点的优先级，一旦有叶结点成为当前扩展结点，就意味着该叶结点所对应的解即为最优解，可以立即终止其余的过程。在前面的例题中曾说明，优先队列的分支限界法更象是有选择、有目的地进行搜索，时间效率、空间效率都是比较高的。 算法总结一个问题是该用递推、贪心、搜索还是动态规划，完全是由这个问题本身阶段间状态的转移方式决定的！每个阶段只有一个状态-&gt;递推；每个阶段的最优状态都是由上一个阶段的最优状态得到的-&gt;贪心；每个阶段的最优状态是由之前所有阶段的状态的组合得到的-&gt;搜索；每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到而不管之前这个状态是如何得到的-&gt;动态规划。 动态规划1.求最优解问题2.整体问题的最优解依赖于各个子问题的最优解3.把大问题分解成小问题，小问题之间还有相互重叠的更小的子问题4.从上往下分析，从下往上求解，避免重复求解小问题]]></content>
      <categories>
        <category>面试题</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F06%2F08%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
